---
title: Python
tags: Notes Computer-Science Python
article_header:
  type: 
  image:
    src: 
---

Python Learning Notes

<!--more-->

# Python基本语法

让Python打印出指定的文字，可以用`print()`函数，然后把希望打印的文字用单引号或者双引号括起来，但不能混用单引号和双引号。


```python
print('hello world!')
```


如果要让用户从电脑输入一些字符，Python提供了`input()`函数，可以让用户输入字符串，并存放到一个变量里。


```python
varName = input()
```

Python的多行代码语法采用缩进方式，写出来的代码风格如下：


```python
a = 100
if a >= 0:
    print(a) #  以井号开头的语句是注释
else:
    print(-a)
```


缩进有利有弊。好处是写出格式化的代码，即坚持使用4个空格的缩进，而且倾向于把一段很长的代码拆分成若干函数，减少缩进数量；坏处是“复制－粘贴”功能不太方便，重构代码时，粘贴的代码必须额外检查缩进是否正确。


此外，Python程序是大小写敏感的，写错了大小写程序会报错。

# 编译与语言对比

## Python解释器


- CPython
默认官方解释器，基于C语言开发，命令行下运行`python`即可启动。
- IPython
基于CPython之上的一个交互式解释器，在交互方式上有所增强，但是执行Python代码的功能和CPython完全一样。
- PyPy
JIT技术，对Python代码进行动态编译（注意不是解释），所以可以显著提高Python代码的执行速度。注意，相同的Python代码在两种解释器下执行可能会有不同的结果。
- Jython
运行在Java平台上的Python解释器，可以直接把Python代码编译成Java字节码执行。
- IronPython
运行在微软.Net平台上的Python解释器，可以直接把Python代码编译成.Net的字节码。

## 和C，Java的语言对比


运行速度：C > Java > Python


C程序是静态语言静态编译，运行前直接编译成CPU能执行的机器码，所以非常快。


Java也是静态语言静态变异，但是运行前需要被JVM这个虚拟机转化成字节码，并解释执行。字节码本身携带了许多编译时信息，使得连接过程更加简单；但缺点是程序运行时执行的是字节码，运行时环境把特化的字节码翻译成对应 CPU架构的机器指令，然后交由CPU读取执行。，因此相比起直接读机器码多了一些额外开销。Java默认是JIT（just-in-time）编译器，当java被编译为字节码形式的class文件之后，他可以在任意的JVM运行；但Java 9之后还引入了AOT（Ahead-Of-Time）编译器，直接生成机器码。主要用于减少JAVA启动预热时间，比较适用于单次执行时间有限需要高效执行的程序，或者是小集成芯片环境，对效率要求比较高。


Python是解释型语言，代码在执行时，期的编译是将 Python 代码编译成解释器可以理解的中间代码，解释器再将中间代码翻译成 CPU 可以理解的机器码。这个过程非常耗时，所以很慢。


C/C提倡low-level control of resources (hardware / system)，让程序员负责更多的控制，而不是让类似 Java 的 Runtime (JVM) 接管太多事情。另一方面，C/C程序对执行传导的立即响应要求上。使用更高级的语言（Java、Python等），对程序员更加容易，不需要担心诸如泄漏之类的错误，也不需要担心如何编译程序或如何确保连接转载正确的库等等。

# 数据类型和变量


Python常见数据类型与C，JAVA等语言类似，包括整数、浮点数、字符串、布尔变量等。此外Python中存在一个空值，用None表示，不能理解为0。


Python变量不仅可以是数字，还可以是任意数据类型，在程序中用一个变量名表示，变量名必须是大小写英文、数字和_的组合，且不能用数字开头。等号`=`表示赋值，可以把任意数据类型赋值给变量，同一个变量可以反复赋值，而且可以是不同类型的变量，例如：


```python
a = 123 #  a是整数
a = 'ABC' #  a变为字符串
```


在Python中，通常用全部大写的变量名表示常量。例如`PI = 3.14159265359`。但事实上这里PI仍然是一个变量，Python根本没有任何机制保证PI不会被改变，用全部大写的变量名表示常量只是一个习惯上的用法。


另外，Python支持复数，语法为x + yj，注意这边的x和y都是用float格式存储：


```python
f = 3+5j

print(f, "is of type", type(f)) # (3+5j) is of type <class 'complex'>
print("real part is", f.real) # real part is 3.0
print("imaginary part is", f.imag) # imaginary part is 5.0
```


# 字符串


在最新的Python 3版本中，字符串是以Unicode编码的，也就是说，Python的字符串支持多语言。


对单个字符的编码，Python提供了`ord()`函数获取字符的整数表示，`chr()`函数把编码转换为对应的字符。由于Python的字符串类型是str，在内存中以Unicode表示，一个字符对应若干个字节。如果要在网络上传输，或者保存到磁盘上，就需要把str变为以字节为单位的bytes。反过来，如果我们从网络或磁盘上读取了字节流，那么读到的数据就是bytes。要把bytes变为str，就需要用`decode()`方法。


Python对bytes类型的数据用带b前缀的单引号或双引号表示：


```python
x = b'ABC'
```


注意区分`'ABC'`和`b'ABC'`，前者是str，后者虽然内容显示得和前者一样，但bytes的每个字符都只占用一个字节。


要计算str包含多少个字符，使用`len()`函数。如果换成bytes，`len()`函数就计算字节数：


```python
len('ABC') # 返回3
len('中文'.encode('utf-8')) # 返回6
```


在Python中，采用的格式化方式和C语言是一致的，用%实现。在字符串内部，%s表示用字符串替换，%d表示用整数替换，有几个%?占位符，后面就跟几个变量或者值，顺序要对应好。如果只有一个%?，括号可以省略。如果字符串里面的%是一个普通字符，就需要转义，用%%来表示一个%。


```python
'%.2f' % 3.1415926 # 输出3.14
```


另一种格式化字符串的方法是使用字符串的format()方法，它会用传入的参数依次替换字符串内的占位符{0}、{1}……：


```python
'Hello, {0}, 成绩提升了 {1:.1f}%'.format('小明', 17.125)
```


# list和tuple


## list


list是一种有序集合，可随时添加和删除其中的元素，形如：


```python
[a, b, c, d]
```


用索引来访问list中每一个位置的元素，且索引是从0开始。当索引超出了范围时，Python会报一个IndexError错误。因此，要确保索引不要越界，记得最后一个元素的索引是`len(classmates) - 1`。


如果要取最后一个元素，除了计算索引位置外，还可以用-1做索引，直接获取最后一个元素。以此类推，可以获取倒数第2个、倒数第3个。


往list中追加元素到末尾，使用`append()` 方法；删除末尾元素用`pop()`方法。两个方法均可以传入索引参数来对具体位置的元素进行操作。另外，可以直接对某个元素进行赋值，来实现修改。


如果要将某个list复制n遍，可以直接使用`list * n`得到复制后的list；如果要合并两个list，可以使用`list1.extend(list2)`方法，直接返回一个合并后的list。


## tuple


tuple和list非常类似，也是一个有序列表，但是tuple一旦初始化就不能修改，即没有`append()` 和`pop()` 等方法，形如：


```python
(a, b, c, d)
```


只有1个元素的tuple定义时必须加一对括号和一个逗号，来消除歧义；而如果有多个元素时，括号可以省略，但元素中间仍需要用逗号分隔：


```python
t = ('a',) 
tupl = 1, 2, 3, 4, 5
```


声明tuple时，可以直接显式地初始化tuple中的每个值，也可以调用tuple()利用其他类型的变量来构造tuple：


```
tpl = ('a','b','c')
another_tpl = tuple('sequence')
```


因为tuple初始化后就不可变，因此元素的顺序也不会变化，可以利用这一特性快速地进行赋值操作：


```python
tpl = ('a','b','c')
x, y, z = tpl

print("value of element x in tuple is", x) # value of element x in tuple is a
print("value of element x in tuple is", y) # value of element x in tuple is b
print("value of element x in tuple is", z) # value of element x in tuple is c
```


tuple的快速复制，元素访问，获取长度以及最值查询等功能与list基本一致，此处省略不提。


# 条件判断


Python种条件判断格式如下：


```python
if <条件判断1>:
    <执行1>
elif <条件判断2>:
    <执行2>
elif <条件判断3>:
    <执行3>
else:+
    <执行4>
```


# 循环


Python的循环有两种。


一种是for...in循环，依次把list或tuple中的每个元素迭代出来：


```python
names = ['Michael', 'Bob', 'Tracy']
for name in names:
    print(name)
```


在这里，生成一个整数范围的list有技巧，使用range()函数，可以生成一个整数序列，再通过list()函数可以转换为list。比如range(5)生成的序列是从0开始小于5的整数。


另一种是while循环，只要条件满足，就不断循环：


```python
sum = 0
n = 99
while n > 0:
    sum = sum + n
    n = n - 2
print(sum)
```


# dict和set


## dict


Python内置了字典：dict的支持，在其他语言中也称为map，使用键-值（key-value）存储，具有极快的查找速度。这种key-value存储方式，在放进去的时候，必须根据key算出value的存放位置，这样，取的时候才能根据key直接拿到value。


把数据放入dict的方法，除了初始化时指定外，还可以通过key放入:


```python
 d['Adam'] = 67
```


由于一个key只能对应一个value，所以，多次对一个key放入value，后面的值会把前面的值冲掉。


如果key不存在，dict就会报错。要避免key不存在的错误，有两种办法，一是通过`in`判断key是否存在；二是通过dict提供的`get(key)`方法，如果key不存在，可以返回None，或者自己指定的value：


```python
'Thomas' in d
    # or
d.get('Thomas', -1) # 返回-1
```


要删除一个key，用`pop(key)`方法，对应的value也会从dict中删除。


和list比较，dict是一种用运行内存换取运行时间的选择：


- 查找和插入的速度极快，不会随着key的增加而变慢；
- 需要占用大量的内存，内存浪费多。



### collections库中的dict拓展


**OrderedDict**


在Python 3.6之前，对dict做迭代时，我们无法确定Key的顺序。collections库中提供了OrderedDict用于解决这一问题。OrderedDict的Key会按照插入的顺序排列，而不是Key本身排序：


```python
od = OrderedDict()
od['z'] = 1
od['y'] = 2
od['x'] = 3
list(od.keys()) # 按照插入的Key的顺序返回

# ['z', 'y', 'x']
```


此外，OrderedDict也可以便捷地引用lambda函数自定义规则进行排序：


```python
od1=  collections.OrderedDict()
od1['one'] = 1
od1['two'] = 2
kvs = [('three',3), ('four',4), ('five',5)]
od1.update(kvs)

od2 = collections.OrderedDict(sorted(od1.items(), key= lambda t : (4*t[1]) - t[1]**2))

# 5, 4, 1, 3, 2
```


**ChainMap**


ChainMap可以把一组dict串起来并组成一个逻辑上的dict。


ChainMap本身也是一个dict，但是查找的时候，会按照顺序在内部的dict依次查找。


```python
dict1= {'a':1, 'b':2, 'c':3}
dict2 = {'d':4, 'e':5}
chainmap = collections.ChainMap(dict1, dict2) # linking two dictionaries

print("print two lined dictionaries", chainmap) # ChainMap({'a': 1, 'b': 2, 'c': 3}, {'d': 4, 'e': 5})
print("print maps for chainmap", chainmap.maps) # [{'a': 1, 'b': 2, 'c': 3}, {'d': 4, 'e': 5}]
print("print values for chainmap", chainmap.values) # <bound method Mapping.values of ChainMap({'a': 1, 'b': 2, 'c': 3}, {'d': 4, 'e': 5})>

print("print value for key 'b'- ",chainmap['b']) # 2
print("print value for key 'e'- ", chainmap['e']) # 5
```


ChainMap非常适合用于应用程序的默认参数设置和用户参数设置，例如，可以先使用一个ChainMap配置默认参数，如果用户有其他设置，就用另一个ChainMap进行override，如果不需要设置了再进行移除，回归默认。这样可以实现参数的优先级查找：


```python
# creates a chainMap with defaults configuration
defaults = {'theme':'Default','language':'eng','showIndex':True, 'showFooter':True}
cm = ChainMap(defaults)   
print("print maps for chainmap", cm.maps) # [{'theme': 'Default', 'language': 'eng', 'showIndex': True, 'showFooter': True}]

# create a new chainMap with a child that overrides the parent
cm2 = cm.new_child({'theme':'bluesky'}) 
print("print maps for another chainmap", cm2.maps) # [{'theme': 'bluesky'}, {'theme': 'Default', 'language': 'eng', 'showIndex': True, 'showFooter': True}]
print("print value for a value theme is", cm2['theme']) # bluesky, because the value has been overridden

# removes the child theme value
cm2.pop('theme')
print("print maps for another chainmap", cm2.maps) # [{}, {'theme': 'Default', 'language': 'eng', 'showIndex': True, 'showFooter': True}]
print("print updated chainmap", cm2['theme']) # Default
```


**Counter**


一个简单的计数器，经常用于一段字符串中每个字符出现次数的统计：


```python
# initialization methods
c1 = Counter('anysequence') # use string, Counter({'e': 3, 'n': 2, 'a': 1, 'y': 1, 's': 1, 'q': 1, 'u': 1, 'c': 1})
c2 = Counter({'a':1, 'c': 1, 'e':3}) # use dict, Counter({'e': 3, 'a': 1, 'c': 1})
c3 = Counter(a=1, c=1, e=3) # use integer, Counter({'e': 3, 'a': 1, 'c': 1})

# update
ct = Counter()  # Counter()
ct.update('abca') # Counter({'a': 2, 'b': 1, 'c': 1})
ct.update({'a':3}) # add a's frequency, Counter({'a': 5, 'b': 1, 'c': 1})
ct.update({'a':-3, 'b':-1, 'e':2})
# another method: ct.subtract({'e':2})

# access
for item in ct:
   print('%s: %d' % (item, ct[item]))

print(ct['x'])

# a: 2
# b: 0
# c: 1
# e: 2
0

# sort
sorted(ct.elements()) # ['a', 'a', 'c', 'e', 'e']
ct.most_common() # Counter({'a': 2, 'c': 1, 'b': 0, 'e': 0})
```


## set


set和dict类似，也是一组key的集合，但不存储value。由于key不能重复，所以，在set中，没有重复的key。创建一个set，需要提供一个list作为输入集合：


```python
s = set([1, 2, 3])
```


通过`add(key)`方法可以添加元素到set中，可以重复添加，但不会有效果。通过`remove(key)`方法可以删除元素。


# 函数


## 函数定义


在Python中，定义一个函数要使用def语句，依次写出函数名、括号、括号中的参数和冒号，然后，在缩进块中编写函数体，函数的返回值用return语句返回。以自定义一个求绝对值的my_abs函数为例：


```python
def my_abs(x):
    if x >= 0:
        return x
    else:
        return -x
```


可以定义一个什么也不做的空函数，使用pass语句：


```python
def nop():
    pass
```


在函数调用时，Python解释器可以检查出传入参数的个数是否正确，但无法检查出每个参数的类型是否正确。所以，应该尽量保证函数定义足够完善，即在定义函数时加入对传入参数的有效性判断。


函数可以返回“多个值”，参考以下实例：


```python
import math

def move(x, y, step, angle=0):
    nx = x + step * math.cos(angle)
    ny = y - step * math.sin(angle)
    return nx, ny

x, y = move(100, 100, 60, math.pi / 6)
print(x, y) # 输出 151.96152422706632 70.0

r = move(100, 100, 60, math.pi / 6)
print(r) # 输出 (151.96152422706632, 70.0)
```


此例中`move()`函数的返回值是一个tuple。在Python语法里，返回一个tuple可以省略括号，而多个变量可以同时接收一个tuple，按位置赋给对应的值，


## 函数参数


参数定义顺序应为：必选参数、默认参数、可变参数、命名关键字参数和关键字参数。


**1.默认参数**


使用默认参数，来简化函数的调用过程。例如计算函数的次幂，可以使用如下函数：


```python
def power(x, n):
    s = 1
    while n > 0:
        n = n - 1
        s = s * x
    return s
```


假如我们经常计算x的平方，便可以把第二个参数n的默认值设定为2，即`def power(x, n=2)`。这样，当我们调用`power(x)`时，相当于调用`power(x, 2)`。设置默认参数时可以遵循两个原则：


- 必选参数在前，默认参数在后
- 有多个参数时，变化大的参数放前面，小的放后面作为默认参数



**2.可变参数**


传入的参数个数是可变的。参考以下函数定义：


```python
def calc(*numbers):
    sum = 0
    for n in numbers:
        sum = sum + n * n
    return sum
```


定义可变参数和定义一个list或tuple参数相比，仅仅在参数前面加了一个*号。在函数内部，参数numbers接收到的是一个tuple，因此，函数代码完全不变。但是，调用该函数时，可以传入任意个参数（包括0）：


```python
calc(1, 2) # 返回5
calc() # 返回0
```


如果已经有一个list或者tuple，Python允许在list或tuple前面加一个*号，把list或tuple的元素变成可变参数传进去：


```python
nums = [1, 2, 3]
calc(*nums)
```


**3.关键字参数**


关键字参数允许传入0个或任意个含参数名的参数，这些关键字参数在函数内部自动组装为一个dict：


```python
def person(name, age, **kw):
    print('name:', name, 'age:', age, 'other:', kw)

#  name:Michael age:30 other: {}
person('Michael', 30) 
#  name: Adam age: 45 other: {'gender': 'M', 'job': 'Engineer'}
person('Adam', 45, gender='M', job='Engineer')
```


关键字参数可以扩展函数的功能。比如，在`person()`函数里，我们保证能接收到name和age这两个参数，但如果调用者愿意提供更多的参数，我们也能收到。试想对于一个类似用户注册的功能，除了用户名和年龄是必填项外，其他都是可选项，利用关键字参数来定义这个函数就能满足注册的需求。**kw参数获得的是一个dict。


**4.命名关键字参数**


如果要限制关键字参数的名字，就可以用命名关键字参数，例如，只接收city和job作为关键字参数。这种方式定义的函数如下：


```python
def person(name, age, *, city, job):
    print(name, age, city, job)
```


和关键字参数**kw不同，命名关键字参数需要一个特殊星号分隔符，后面的参数被视为命名关键字参数。如果缺少，Python解释器将无法识别位置参数和命名关键字参数：


```python
person('Jack', 24, city='Beijing', job='Engineer')
#  Jack 24 Beijing Engineer
```


命名关键字参数必须传入参数名，否则调用将报错。


## 递归函数


如果一个函数在内部调用自身本身，这个函数就是递归函数。例如计算阶乘n! ，用函数`fact(n)`表示如下：


```python
def fact(n):
    if n == 1:
        return 1
    return n * fact(n - 1)
```


递归函数的优点是定义简单，逻辑清晰。然而，函数调用通过栈这种数据结构实现的，每进入一个函数调用，栈就会加一层栈帧，函数返回时栈减一层栈帧。由于栈的大小不是无限的，所以，递归调用的次数过多会导致栈溢出。


解决递归调用栈溢出的方法是通过尾递归优化。尾递归指在函数返回的时候调用自身，并且，return语句不能包含表达式。尾递归使得递归本身无论调用多少次，都只占用一个栈帧，不会出现栈溢出的情况。例如此前的程序可修改：


```python
def fact(n):
    return fact_iter(n, 1)

def fact_iter(num, product):
    if num == 1:
        return product
    return fact_iter(num - 1, num * product)
```


`return fact_iter(num - 1, num * product)`仅返回递归函数本身，num - 1和num * product在函数调用前就会被计算，不影响函数调用。


遗憾的是，大多数编程语言没有针对尾递归做优化，Python也不例外。即使把上面的`fact(n)`函数改成尾递归方式，也会导致栈溢出。


# 函数高级特性


## 切片


切片指取一个list或tuple中的部分元素，用`L[a:b]`表示，从索引a开始取，直到索引b为止，但不包括索引b。例如对于如下一个list:


```python
L = ['Michael', 'Sarah', 'Tracy', 'Bob', 'Jack']
L[0:3] # 返回['Michael', 'Sarah', 'Tracy']
L[:3] # 第一个索引是0时可以省略，因此L[:3] 和 L[0:3]效果一致。
L[:] # 返回L本身
```


类似地，Python支持以类似`L[-1]`的语法取最后一个元素，也同样支持倒数切片：


```python
 L[-2:] # 返回['Bob', 'Jack']
 L[-2:-1] # 返回['Bob']
```


如果再加入一个参数c，即写成类似`L[a:b:c]`的形式，则表示在[a, b)区间里，每隔c个数取一个元素。例如集合L为0~99所有整数，要每隔5个数取一个数出来：


```python
L[::5]
# 返回[0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95]
```


tuple也支持切片操作，只是操作的结果仍是tuple：


```python
(0, 1, 2, 3, 4, 5)[:3] #  返回(0, 1, 2)
```


一个字符串也可以看成是一个list，每个元素就是一个字符。因此，字符串也支持切片操作，操作结果也仍是字符串：


```python
'ABCDEFG'[:3] # 返回'ABC'
```


## 迭代


在Python中，迭代通过for ... in结构完成。在Python中只要是可迭代对象，无论有无下标，都可以迭代，比如dict就可以迭代：


```python
d = {'a': 1, 'b': 2, 'c': 3}

#  迭代key
for key in d:
	print(key)

#  迭代value
for value in d.values():
    print(value)

#  key, value一起迭代
for k, v in d.items():
    print(k, v)
```


需要注意，dict的存储不按照list的方式顺序排列，因此迭代出的结果顺序可能不一样。


要判断一个对象是可迭代对象呢，可以通过collections模块的Iterable类型判断：


```python
from collections import Iterable
isinstance('abc', Iterable) #  str可迭代，返回True
isinstance([1,2,3], Iterable) #  list可迭代，返回True
isinstance(123, Iterable) #  整数不可迭代，返回False
```


若要对list实现下标循环，使用`enumerate()`函数可以把一个list变成索引-元素对，这样就能在for循环中同时迭代索引和元素本身：


```python
for i, value in enumerate(['A', 'B', 'C']):
	print(i, value)
#  输出
0 A
1 B
2 C
```


## 列表生成式


列表生成式是Python内置的一种便捷生成list的方法。例如要生成list [1x1, 2x2, 3x3, ..., 10x10]，只需要把要生成的元素x * x放到前面，后面跟for循环，就可以把list创建出来。：


```python
[x * x for x in range(1, 11)]
```


for 循环后面还可以加上if判断，这样我们就可以筛选出仅偶数的平方：


```python
[x * x for x in range(1, 11) if x % 2 == 0]
```


还可以使用两层循环生成全排列：


```python
[m + n for m in 'ABC' for n in 'XYZ'] 
#  ['AX', 'AY', 'AZ', 'BX', 'BY', 'BZ', 'CX', 'CY', 'CZ']
```


## 生成器


list容量是有限的，且创建一个包含很多元素的列表将占用很大的存储空间。如果我们仅需要访问前几个元素，那后面绝大多数元素占用的空间都白白浪费了。所以，如果列表元素可以按照某种算法推算出来，便可以在循环的过程中不断推算出后续的元素，不必创建完整的list，节省大量的空间。在Python中，这种一边循环一边计算的机制称为生成器：generator。


创建一个generator有多种方法。最简单的是把一个列表生成式的[]改成()：


```python
L = [x * x for x in range(10)]
# 返回[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]
g = (x * x for x in range(10))
# 返回<generator object <genexpr> at 0x1022ef630>

#  可使用for循环迭代访问
for n in g:
    print(n)
#  输出
0
1
4
9
16
25
36
49
64
81
```


如果一个函数定义中包含`yield`关键字，那么这个函数就不再是一个普通函数，而是一个generator。以生成斐波那契数列为例：


```python
def fib(max):
    n, a, b = 0, 0, 1
    while n < max:
        yield b
        a, b = b, a + b
        n = n + 1
    return 'done'
```


变成generator的函数，在每次调用`next()`的时候执行，遇到`yield`语句返回，再次执行时从上次返回的`yield`语句处继续执行。


## 迭代器


可以被`next()`函数调用并不断返回下一个值的对象称为迭代器：Iterator。Python的Iterator对象表示的是一个数据流，Iterator对象可以被`next()`函数调用并不断返回下一个数据，直到没有数据时抛出StopIteration错误。可以把这个数据流看做是一个有序序列，但我们却不能提前知道序列的长度，只能不断通过调用`next()`函数实现按需计算下一个数据，所以Iterator的计算是惰性的，只有在需要返回下一个数据时它才会计算。


生成器都是Iterator对象。而list、dict、str等结构虽然Iterable，却不是Iterator。因为Iterator甚至可以表示一个无限大的数据流，例如全体自然数。而使用list等结构是永远不可能存储无限大的数据流的。


Python的for循环本质上就是通过不断调用`next()`函数实现的。例如：


```python
for x in [1, 2, 3, 4, 5]:
    pass
```


等价于


```python
#  首先获得Iterator对象:
it = iter([1, 2, 3, 4, 5])
#  循环:
while True:
    try:
        #  获得下一个值:
        x = next(it)
    except StopIteration:
        #  遇到StopIteration就退出循环
        break
```


# 函数式编程


## 高阶函数


函数本身可以赋值给变量，即：变量可以指向函数；而函数的参数原本就能接收变量。如此，一个函数就可以接收另一个函数作为参数。这种函数称为高阶函数。以绝对值函数`abs()`为例，我们可以把函数名`abs`看成变量，它指向一个可以计算绝对值的函数：


```python
x = abs(-10)
f = abs
# 此时f为<built-in function abs>

f(-10) # 返回10

def add(x, y, f):
    return f(x) + f(y)

add(-5, 6, abs) #  返回11
```


### map/reduce


`map()`函数接收两个参数，一个是函数，一个是Iterable类的对象。`map()`将传入的函数依次作用到对象中的每个元素，并把结果作为新的Iterator返回。例如将函数f(x)=x * x作用在一个list [1, 2, 3, 4, 5, 6, 7, 8, 9]上，就可以用`map()`实现：


```python
 def f(x):
     return x * x    
 r = map(f, [1, 2, 3, 4, 5, 6, 7, 8, 9])
 list(r) # 返回[1, 4, 9, 16, 25, 36, 49, 64, 81]
```


`reduce()`把一个函数作用在一个序列[x1, x2, x3, ...]上，把结果继续和序列的下一个元素做累积计算，其效果为：


```python
reduce(f, [x1, x2, x3, x4]) = f(f(f(x1, x2), x3), x4)
```


例如序列求和就可以用`reduce()`实现：


```python
from functools import reduce
def add(x, y):
	return x + y
reduce(add, [1, 3, 5, 7, 9]) # 返回25
```


或是将序列[1, 3, 5, 7, 9]变换成整数13579：


```python
from functools import reduce
def fn(x, y):
    return x * 10 + y

def char2num(s):
	return {'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9}[s]

reduce(fn, map(char2num, '13579')) # 返回13579
```


### filter


`filter()`接收一个Boolean函数和一个序列，把传入的函数依次作用于每个元素，根据返回值是True还是False决定保留还是丢弃该元素。例如，在一个list中，删掉偶数，只保留奇数，可以这么写：


```python
def is_odd(n):
    return n % 2 == 1

list(filter(is_odd, [1, 2, 4, 5, 6, 9, 10, 15]))
#  返回 [1, 5, 9, 15]
```


### sorted


Python内置的`sorted()`函数可以对list进行排序，并且还可以接收一个key函数来实现自定义规则排序：


```python
sorted([36, 5, -12, 9, -21]) # 返回[-21, -12, 5, 9, 36]
sorted([36, 5, -12, 9, -21], key=abs) # 按绝对值大小排序，返回[5, 9, -12, -21, 36]
# 忽略大小写排序，返回['about', 'bob', 'Credit', 'Zoo']
sorted(['bob', 'about', 'Zoo', 'Credit'], key=str.lower)
```


## 返回函数(闭包)


Python中可以把函数作为结果值返回。


例如对于一个求和操作，可以不返回求和的结果，而是返回求和的函数：


```python
def lazy_sum(*args):
    def sum():
        ax = 0
        for n in args:
            ax = ax + n
        return ax
    return sum

f = lazy_sum(1, 3, 5, 7, 9)
# 返回 <function lazy_sum.<locals>.sum at 0x101c6ed90>
f() # 返回25
```


当我们调用`lazy_sum()`时，返回的实质上是`sum()`函数。只有调用函数`f()`时，才真正计算求和的结果。


在这个例子中，`lazy_sum()`函数中定义了函数`sum()`，且内部函数`sum()`可以引用外部函数`lazy_sum()`的参数和局部变量，当`lazy_sum()`返回函数`sum()`时，相关参数和变量都保存在返回的函数中。这种结构称为闭包。


注意：


- 返回函数不要引用任何循环变量，或者后续会发生变化的变量，因为返回的函数不会立即执行，会等到具体被调用了才执行，等到函数都返回时，引用的变量已经不是预期的了。要解决这个问题，可以再创建一个函数，用该函数的参数绑定循环变量当前的值，无论该循环变量后续如何更改，已绑定到函数参数的值不变。当然这样会使得代码量显著增加
```python
def count():
    def f(j):
        def g():
            return j*j
        return g
fs = []
for i in range(1, 4):
    fs.append(f(i)) # f(i)立刻被执行，因此i的当前值被传入f()
return fs

"""
>>> f1, f2, f3 = count()
>>> f1()
1
>>> f2()
4
>>> f3()
9
"""
```

- 闭包无法直接访问、修改外部函数的局部变量
- 每次调用都会返回一个新的函数。以上面的`lazy_sum()`为例，即使两次传入相同的参数，这两个函数也是实际上不同的函数



闭包的作用：


- 局部变量会常驻在内存中，闭包执行完后，仍然能够保持住当前的运行环境（走棋子，每次走完一步保留上一步的位置）
- 能够避免很多需要使用全局变量的场合，因为内部函数总是可以访问其所在的外部函数中声明的参数和变量，即使在其外部函数被返回（寿命终结）了之后。



## 匿名函数


有时候不需要显式地定义函数，直接传入匿名函数更方便。仍以`map()`函数为例，套用f(x)=x * x时，除了定义一个f(x)的函数外，还可以直接传入匿名函数：


```python
list(map(lambda x: x * x, [1, 2, 3, 4, 5, 6, 7, 8, 9]))
# 返回[1, 4, 9, 16, 25, 36, 49, 64, 81]
```


匿名函数只能有一个表达式，且不写`return`，返回值就是该表达式的结果。匿名函数也是一个函数对象，因此可以赋值给一个变量，再利用变量来调用该函数：


```python
f = lambda x: x * x
f  # 返回<function <lambda> at 0x101c6ef28>
f(5) # 返回25
```


## 装饰器


在代码运行期间动态增加功能的方式称为装饰器(decorator)。


面向对象的设计模式中，decorator被称为装饰模式，通过继承和组合来实现，而Python除了能支持面向对象的decorator外，还可以直接从语法层次支持decorator。


假如我们有一个函数，用来打印当前的日期：


```python
def now():
    print('2020-01-01')
```


假设我们要增强`now()`函数的功能，比如，在函数调用前后自动打印日志，但又不希望修改`now()`函数的定义，我们可以定义一个能打印日志的decorator函数`log()`：


```python
def log(func):
    def wrapper(*args, **kw):
        print('call %s():' % func.__name__)
        return func(*args, **kw)
    return wrapper
```


因为它是一个decorator，所以接受一个函数作为参数，并返回一个函数。我们要借助Python的`@`语法，把decorator置于函数的定义处。之后在调用`now()`的时候，不仅会运行`now()`本身，还会在运行`now()`前打印一行日志：


```python
@log
def now():
    print('2020-01-01')

# >>> now()
# call now():
# 2020-01-01
```


1. 把`@log`放到`now()`函数的定义处，相当于执行了语句`now = log(now)`
2. 由于`log()`是一个decorator，返回一个函数，所以，原来的`now()`函数仍然存在，只是现在同名的now变量指向了新的函数，于是调用`now()`将执行新函数，即在`log()`函数中返回的`wrapper()`函数
3. `wrapper()`函数的参数定义是`(*args, **kw)`，因此，`wrapper()`函数可以接受任意参数的调用。在`wrapper()`函数内，首先打印日志，再紧接着调用原始函数。



## 偏函数


当函数的参数个数太多，需要简化时，可以使用`functools.partial()`函数把某些参数给固定住（即设置默认值），返回一个新的函数。调用这个新函数时便可以传入更少的参数。


例如，`int()`函数可以把字符串转换为整数，提供额外的base参数，默认值为10。假设要转换大量的二进制字符串，每次都传入`int(x, base=2)`非常麻烦，便可以使用创建一个名为`int2()`的偏函数，默认把`base=2`传进去：


```python
import functools
int2 = functools.partial(int, base=2)

int2('1000000') # 返回64
```


创建偏函数时，实际上可以接收函数对象、`*args`和`**kw`这3个参数。例如对于`max()`函数，当定义如下偏函数时，会把10作为`*args`的一部分加入到左边，例如：


```python
max2 = functools.partial(max, 10)

max2(5, 6, 7)
#  等同于
args = (10, 5, 6, 7)
max(*args) # 返回10
```


# 模块


为了编写可维护的代码，我们把很多函数分组，分别放到不同的文件里，这样每个文件包含的代码相对较少。在Python中，一个.py文件就称之为一个模块（Module）。


使用模块好处是提高了代码的可维护性，且编写代码不必从零开始。当一个模块编写完毕，就可以被其他地方引用。此外，使用模块还可以避免函数名&变量名冲突，因为相同名字的函数和变量可以分别存在不同的模块中。


为避免模块名冲突，Python又引入了按目录来组织模块的方法，称为包（Package）。只要顶层的包名不与别人冲突，所有模块都不会与别人冲突。每一个包目录下面都有一个 __init__.py的文件，这个文件是必须存在的，否则，Python会这个目录当成普通目录。


Python本身内置了很多有用的模块，当Python安装完毕后这些模块就可以立刻被使用。例如以内建的sys模块编写一个hello world的模块：


```python
#  -*- coding: utf-8 -*-

#  导入一个模块，即拥有一个变量指向该模块，利用这个变量访问模块功能
import sys

def hello():
    #  sys模块的argv变量用list存储命令行所有参数
    #  argv至少有一个元素，即当前.py文件的名称
    if len(sys.argv) == 1:
        print('Hello world')
    elif len(sys.argv) == 2:
        print('Hello %s' % args[1])
    else:
        print('Too many arguments!')

#  当我们在命令行运行hello模块文件时，Python解释器把一个特殊变量__name__置为__main__
#  如果在其他地方导入该hello模块时，if判断将失败
if __name__=='__main__':
    hello()
```


我们给这个文件命名为`hello.py`，使用命令行运行：


```python
$ python3 hello.py
Hello world
$ python hello.py Mike
Hello Mike
```


也可以启动Python交互环境，再导入hello模块：


```python
import hello
hello.hello() # 输出 Hello World
```


在一个模块中，我们可能会定义很多函数和变量，但有的函数和变量我们希望给别人使用，有的函数和变量我们希望仅仅在模块内部使用。Python中通过`_`前缀表示模块内部使用函数或变量。尽管Python并不能完全限制访问private函数或变量，但从编程习惯上仍不应引用private函数或变量。


# 面向对象编程


## 类和实例


在自然界中，类(Class)是一种抽象概念，比如我们定义Student类泛指学生这个概念，而实例（Instance）则是一个个具体的Student。类名通常是大写开头的单词。类定义的参数object则表示该类是从哪个类继承下来的。


创建实例的时候，需要将我们认为必须绑定的属性强制填写进去。这一过程在初始化__init__方法中实现。例如，创建学生实例的时候，需要绑定name，score等属性：


```python
class Student(object):
    #  __init__的第一个参数永远为self，self指向创建的实例本身
    def __init__(self, name, score):
        self.name = name
        self.score = score
```


在Student类中，每个实例拥有各自的name和score这些数据。我们可以定义函数来访问这些数据。例如打印一个学生的成绩：


```python
def print_score(std):
	print('%s: %s' % (std.name, std.score))
```


从Student类的定义来看，外部代码可以自由地修改一个实例的name、score属性。如果要让这些属性不被外部访问，需要在属性的名称前加上两个下划线__。Python中，实例的变量名如果以__开头，就变成了一个私有变量，即只有内部可以访问，外部不能访问：


```python
class Student(object):
    def __init__(self, name, score):
        self.__name = name
        self.__score = score

    def print_score(self):
        print('%s: %s' % (self.__name, self.__score))
```


如果外部代码要获取name和score，则可以给Student类增加`get_name()`和`get_score()`的方法：


```python
def get_name(self):
        return self.__name

    def get_score(self):
        return self.__score
```


## 继承与多态


当我们定义一个类的时候，可以从某个现有的类继承，新的类称为子类（Subclass），而被继承的类称为基类、父类或超类。比如，我们已经编写了一个名为Animal的类，有一个`run()`方法可以直接打印：


```python
class Animal(object):
    def run(self):
        print('Animal is running...')
```


当我们编写Animal的两个子类Dog和Cat类时，由于Animal实现了`run()`方法，因此，Dog和Cat作为它的子类，定义时也自动拥有了`run()`方法：


```python
class Dog(Animal):
    pass

class Cat(Animal):
    pass

dog = Dog()
dog.run() # 返回Animal is running...

cat = Cat()
cat.run() # 返回Animal is running...
```


对于一个Animal类型的变量，我们无需确切地知道它的子类型就可以放心地调用run()方法，而具体调用时由运行时该对象的确切类型决定，这便是多态真正的威力：调用方只管调用，不管细节。即便们再新增一种Animal的子类，只要确保run()方法编写正确，便不用管原来的代码是如何调用的。这就是著名的“开闭”原则：


- 对扩展开放：允许新增Animal子类；
- 对修改封闭：不需要修改依赖Animal类型的`run()`等函数。



最后，对于静态语言（例如Java）来说，如果需要传入Animal类型，则传入的对象必须是Animal类或者它的子类，否则，将无法调用`run()`方法；对于Python这样的动态语言来说，则不一定需要传入Animal类型。我们只需要保证传入的对象有一个`run()`方法就可以了。这就是动态语言的“鸭子类型”，它并不要求严格的继承体系，一个对象只要“看起来像鸭子，走起路来像鸭子”，那它就可以被看做是鸭子。


## 获取对象信息


判断对象类型，使用`type()`函数：


```python
type(123)
# 返回 <class 'int'>

type('str')
# 返回 <class 'str'>

type(None)
# 返回 <type(None) 'NoneType'>

type(abs)
# 返回 <class 'builtin_function_or_method'>
```


对类的继承关系来说，使用`type()`很不方便，可以使用`isinstance()`函数。能用`type()`判断的基本类型也可以用`isinstance()`判断。例如，如果继承关系是：object -> Animal -> Dog -> Husky，则：


```python
h = Husky()
isinstance(h, Dog) # 返回 True
isinstance('a', str) # 返回True
isinstance(b'a', bytes) # 返回True
```


## 类属性


如果类本身需要绑定一个属性，可以直接在类中定义，这种属性便是类属性。例如，要在Student类中定义一个名字的类属性：


```python
class Student(object):
    name = 'Student'
```


当定义了一个类属性后，这个属性虽然归类所有，但类的所有实例都可以访问到。需要注意，实例属性优先级比类属性高，因此如果产生命名冲突，它会屏蔽掉类属性。


## 使用__slots__


如果想要限制实例的属性，例如只允许对Student类实例添加name和age属性，需要在定义类的时候添加一个特殊的`__slots__`变量，来限制该class实例能添加的属性。如果试图绑定一个未放入`__slots__`的属性，会产生AttributeError：


```python
class Student(object):
    __slots__ = ('name', 'age') #  用tuple定义允许绑定的属性名称

s.score = 99
# 输出
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
AttributeError: 'Student' object has no attribute 'score'
```


使用`__slots__`要注意，`__slots__`定义的属性仅对当前类实例起作用，对继承的子类是不起作用的。


## 使用[@property ](/property )


`@property`广泛应用在类的定义中，既能检查参数，又可以用类似属性这样简单的方式来访问类的变量。Python内置的`@property`装饰器就是负责把一个方法变成属性调用的。


把一个getter方法变成属性，只需要加上`@property`就可以了，此时，`@property`本身又创建了另一个装饰器`@score.setter`，负责把一个setter方法变成属性赋值，于是，我们就拥有一个可控的属性操作：


```python
class Student(object):
    @property
    def score(self):
        return self._score

    @score.setter
    def score(self, value):
        if not isinstance(value, int):
            raise ValueError('score must be an integer!')
        if value < 0 or value > 100:
            raise ValueError('score must between 0 ~ 100!')
        self._score = value


s = Student()
s.score = 60 #  setter
s.score #  getter，返回60
s.score = 9999 #  报错，超出范围
```


## 多重继承


倘若要给动物再加上Runnable和Flyable的功能，只需要先定义好Runnable和Flyable的类，再让动物继承相应的类即可：


```python
class Runnable(object):
    def run(self):
        print('Running...')

class Flyable(object):
    def fly(self):
        print('Flying...')

class Dog(Mammal, Runnable):
    pass
```


如果某个类需要加入额外的功能，可以通过多重继承实现。比如，Ostrich除了继承Bird外，再同时继承Runnable。这种设计称为MixIn。MixIn的目的是给一个类增加多个功能，设计类的时候，我们优先考虑通过多重继承来组合多个MixIn的功能，而不是设计多层次的复杂继承关系。


## 定制类


如果一个类想被用于`for ... in`循环，就必须实现一个`__iter__()`方法，该方法返回一个迭代对象。Python的for循环就会不断调用该迭代对象的`__next__()`方法拿到循环的下一个值，直到遇到`StopIteration`错误时退出循环。以斐波那契数列为例，写一个Fib类，可以作用于for循环：


```python
class Fib(object):
    def __init__(self):
        self.a, self.b = 0, 1 #  初始化两个计数器a，b

    def __iter__(self):
        return self #  实例本身就是迭代对象，故返回自己

    def __next__(self):
        self.a, self.b = self.b, self.a + self.b #  计算下一个值
        if self.a > 100000: #  退出循环的条件
            raise StopIteration()
        return self.a #  返回下一个值

for n in Fib():
    print(n)
#  输出
1
1
2
3
5
...
46368
75025
```


若要像list那样按照下标取出元素，需要实现`__getitem__()`方法：


```python
class Fib(object):
    def __getitem__(self, n):
        a, b = 1, 1
        for x in range(n):
            a, b = b, a + b
        return a
```


此外，如果把对象看成dict，`__getitem__()`的参数也可能是一个可以作key的object，例如str。与之对应的是`__setitem__()`方法，把对象视作list或dict来对集合赋值。最后，还有一个`__delitem__()`方法，用于删除某个元素。这些方法使我们自己定义的类表现得和Python自带的list、tuple、dict没什么区别，这完全归功于动态语言的“鸭子类型”。


Python还有一个`__getattr__()`方法，动态返回一个属性。例如:


```python
class Student(object):
    def __init__(self):
        self.name = 'Mike'

    def __getattr__(self, attr):
        if attr == 'score':
            return 99

s = Student()
s.name # 返回Mike
s.score # 返回99
```


当调用不存在的属性时，比如score，Python解释器会试图调用`__getattr__(self, 'score')`来尝试获得属性，这样，我们就有机会返回score的值。


一个对象实例可以有自己的属性和方法，当我们调用实例方法时，我们既可以用`instance.method()`来调用，也可以直接在实例本身上调用。实际上在Python中，任何类只需要定义一个`__call__()`方法，就可以实现后者：


```python
class Student(object):
    def __init__(self, name):
        self.name = name

    def __call__(self):
        print('My name is %s.' % self.name)

s = Student('Mike')
s() # 返回 My name is Mike.
```


`__call__()`还可以定义参数。对实例进行直接调用就好比对一个函数进行调用一样，所以完全可以把对象看成函数，把函数看成对象。


## 枚举类


当我们需要定义常量时，可以为枚举类型定义一个class类型，每个常量都是class的一个唯一实例。Python提供了Enum类来实现这个功能。例如对于月份类，可以按如下操作：


```python
from enum import Enum

Month = Enum('Month', ('Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'))

for name, member in Month.__members__.items():
    print(name, '=>', member, ',', member.value)
```


这样我们就获得了Month类型的枚举类，可以直接使用Month.Jan来引用一个常量，或者枚举它的所有成员。


如果需要更精确地控制枚举类型，可以从Enum派生出自定义类。`@unique`装饰器可以帮助我们检查保证没有重复值。：


```python
from enum import Enum, unique

@unique
class Weekday(Enum):
    Sun = 0 #  Sun的value被设定为0
    Mon = 1
    Tue = 2
    Wed = 3
    Thu = 4
    Fri = 5
    Sat = 6
```


## 动态创建类与元类


`type()`函数既可以返回一个对象的类型，又可以创建出新的类型。通过`type()`函数创建的类和直接定义类是完全一样的，因为Python解释器遇到类定义时，实质上也是调用`type()`函数创建出类。比如，我们可以通过`type()`函数创建出Hello类：


```python
def fn(self, name='world'): #  先定义函数
    print('Hello, %s.' % name)

Hello = type('Hello', (object,), dict(hello=fn)) #  创建Hello class
h = Hello()
h.hello() #  返回Hello, world.
```


要创建一个class对象，type()函数依次传入3个参数：


- 类的名称；
- 继承的父类集合，以tuple形式表示；
- 方法名称与函数绑定，例如这里我们把函数`fn()`绑定到Hello上。



除了使用type()动态创建类以外，要控制类的创建行为，还可以使用metaclass。metaclass允许你创建类或者修改类。换句话说，你可以把类看成是metaclass创建出来的“实例”。在实现ORM（“Object Relational Mapping”，即对象-关系映射，就是把关系数据库的一行映射为一个对象，也就是一个类对应一个表）框架等场景下，往往需要这个功能。


# 错误、调试、测试


## 异常处理


高级语言通常都内置了一套`try...except...finally...`的错误处理机制，Python也不例外。
用一个例子来看看try的机制：


```python
try:
    print('try...')
    r = 10 / 0
    print('result:', r)
except ZeroDivisionError as e:
    print('except:', e)
finally:
    print('finally...')
print('END')
```


当我们认为某些代码可能会出错时，就可以用`try`来运行这段代码，如果执行出错，则后续代码不会继续执行，而是直接跳转至错误处理代码，即`except`语句块，执行完`except`后，如果有`finally`语句块，则执行`finally`语句块，至此，执行完毕。


此外，如果没有错误发生，可以在`except`语句块后面加一个`else`，当没有错误发生时，会自动执行`else`语句：


```python
try:
    print('try...')
    r = 10 / int('2')
    print('result:', r)
except ValueError as e:
    print('ValueError:', e)
except ZeroDivisionError as e:
    print('ZeroDivisionError:', e)
else:
    print('no error!')
finally:
    print('finally...')
print('END')
```


Python的错误其实也是类，所有的错误类型都继承自`BaseException`，所以在使用`except`时需要注意的是，它不但捕获该类型的错误，还把其子类也一网打尽。错误并不是凭空产生的，而是有意创建并抛出的。Python的内置函数会抛出很多类型的错误，我们自己编写的函数也可以抛出错误。


## 调试


调试有多种方法。最简单的是用`print()`把可能有问题的变量打印出来检查。如果要更专业一些，可以用`assert()`来替代`print()`：


```python
def foo(s):
    n = int(s)
    assert n != 0, 'n is zero!'
    return 10 / n

def main():
    foo('0')
```


在这个例子中，`assert`的意思是，表达式n != 0应该是True，否则，根据程序运行的逻辑，后面的代码肯定会出错。注意`assert`语句本身就会抛出`AssertionError`。


把`print()`替换为`logging`是第三种方式，和`assert`比，`logging`不会抛出错误，而且可以输出到文件。`logging.info()`就可以输出一段文本。：


```python
import logging

s = '0'
n = int(s)
logging.info('n = %d' % n)
print(10 / n)
```


`logging`允许制定记录信息的级别，有`debug`，`info`，`warning`，`error`等几个级别，当指定`level=INFO`时，`logging.debug`就不起作用了。同理，指定`level=WARNING`后，`debug`和`info`就不起作用了。这样一来，可以放心地输出不同级别的信息，也不用删除，最后统一控制输出哪个级别的信息：


```python
import logging
logging.basicConfig(level=logging.INFO)

$ python3 err.py
INFO:root:n = 0
Traceback (most recent call last):
  File "err.py", line 8, in <module>
    print(10 / n)
ZeroDivisionError: division by zero
```


还可以启动Python的调试器pdb，让程序以单步方式运行，随时查看运行状态。程序如下：


```python
#  err.py
s = '0'
n = int(s)
print(10 / n)
```


以参数-m pdb启动后，pdb定位到下一步要执行的代码-> s = '0'。


```python
$ python3 -m pdb err.py
> err.py(2)<module>()
-> s = '0'
```


输入命令l来查看代码：


```python
(Pdb) l
  1     #  err.py
  2  -> s = '0'
  3     n = int(s)
  4     print(10 / n)
```


输入命令n可以单步执行代码：


```python
(Pdb) n
> err.py(3)<module>()
-> n = int(s)
(Pdb) n
> err.py(4)<module>()
-> print(10 / n)
```


任何时候都可以输入命令p 变量名来查看变量：


```python
(Pdb) p s
'0'
(Pdb) p n
0
```


输入命令q结束调试，退出程序：


```python
(Pdb) q
```


## 单元测试


单元测试对一个模块、一个函数或者一个类来进行正确性检验。如果单元测试通过，说明我们测试的这个函数能够正常工作。否则说明要么函数有bug，要么测试条件输入不正确。这种以测试为驱动的开发模式最大的好处就是确保一个程序模块的行为符合我们设计的测试用例。


对每一类测试都需要编写一个test_xxx()方法。由于`unittest.TestCase`提供了很多内置的条件判断，我们只需要调用这些方法就可以断言输出是否是我们所期望的。最常用的断言就是`assertEqual()`：


```python
self.assertEqual(abs(-1), 1) # 断言函数返回的结果与1相等
```


另一种重要的断言就是期待抛出指定类型的Error，比如通过d['empty']访问不存在的key时，断言会抛出KeyError：


```python
with self.assertRaises(KeyError):
    value = d['empty']
```


一旦编写好单元测试，我们就可以运行单元测试。最简单的运行方式是在mydict_test.py的最后加上两行代码，这样就可以把测试文件当做正常的python脚本运行：


```python
if __name__ == '__main__':
    unittest.main()
```


可以在单元测试中编写两个特殊的`setUp()`和`tearDown()`方法。这两个方法会分别在每调用一个测试方法的前后分别被执行。例如测试需要启动一个数据库，这时，就可以在`setUp()`方法中连接数据库，在`tearDown()`方法中关闭数据库，这样，不必在每个测试方法中重复相同的代码：


```python
class TestDict(unittest.TestCase):

    def setUp(self):
        print('setUp...')

    def tearDown(self):
        print('tearDown...')
```


# IO编程


## 文件读写


读写文件就是请求操作系统打开一个文件对象（通常称为文件描述符），然后，通过操作系统提供的接口从这个文件对象中读取数据（读文件），或者把数据写入这个文件对象（写文件）。


要以读文件的模式打开一个文件对象，使用Python内置的open()函数，传入文件名和标示符。标示符'r'表示读（类似地，'rb'表示读   二进制文件），这样，我们就成功地打开了一个文件：


```python
>>> f = open('/Users/michael/test.txt', 'r')
```


如果文件打开成功，接下来，调用`read()`方法可以一次读取文件的全部内容，Python把内容读到内存，用一个str对象表示：


```python
>>> f.read()
'Hello, world!'
```


如果文件不存在，open()函数就会抛出一个IOError的错误，并且给出错误码和详细的信息告诉你文件不存在。由于文件读写时都有可能产生IOError，一旦出错，后面的`f.close()`就不会调用。所以，为了保证无论是否出错都能正确地关闭文件，我们可以搭配try ... finally来实现文件读写；或者也可以使用更简单的`with`写法，保证容错的同时精简代码：


```python
with open('/path/to/file', 'r') as f:
    print(f.read())
```


注意，文件使用完毕后必须调用`close()`方法关闭文件，因为文件对象会占用操作系统的资源，并且操作系统同一时间能打开的文件数量也是有限的。


在读文件的时候，也要注意根据文件类型选择读取函数：


```python
read() # 适合小文件一次性读取
read(size) # 反复多次读取一个大文件
readline() # 每次读取一行内容
readlines() # 一次读取所有内容并按行返回list
```


写文件与读文件基本一致，区别是模式从'r'变成了'w'，函数从`read()`变成了`write()`。注意以'w'模式写入文件时，如果文件已存在，会直接覆盖（相当于删掉后新写入一个文件）。如果我们希望追加到文件末尾怎么办？可以传入'a'以追加（append）模式写入。


## StringIO和BytesIO


很多时候，数据读写不一定是文件，也可以在内存中读写。StringIO顾名思义就是在内存中读写str，要把str写入StringIO，我们需要先创建一个StringIO，然后，像文件一样写入即可：


```python
>>> from io import StringIO
>>> f = StringIO()
>>> f.write('hello')
5
>>> f.write(' ')
1
>>> f.write('world!')
6
>>> print(f.getvalue()) # 获得写入后的str
hello world!
```


要读取StringIO，可以用一个str初始化StringIO，然后，像读文件一样读取：


```python
>>> from io import StringIO
>>> f = StringIO('Hello!\nHi!\nGoodbye!')
>>> while True:
...     s = f.readline()
...     if s == '':
...         break
...     print(s.strip())
...
Hello!
Hi!
Goodbye!
```


StringIO操作的只能是str，如果要操作二进制数据，就需要使用BytesIO，使用方法与StringIO类似：


```python
# write
>>> from io import BytesIO
>>> f = BytesIO()
>>> f.write('中文'.encode('utf-8'))
6
>>> print(f.getvalue())
b'\xe4\xb8\xad\xe6\x96\x87'


# read
>>> from io import BytesIO
>>> f = BytesIO(b'\xe4\xb8\xad\xe6\x96\x87')
>>> f.read()
b'\xe4\xb8\xad\xe6\x96\x87'
```


## 操作文件和目录


Python内置的`os`模块可以直接调用操作系统提供的接口函数。


在操作系统中定义的环境变量，全部保存在`os.environ`中，可以直接查看，或者调用`os.environ.get('key')`使用某一个环境变量。


其他一些路径相关的函数：


- `os.path.abspath('.')`：当前目录绝对路径
- `os.mkdir('xxx')`：创建一个目录
- `os.rmdir('xxx')`：删除一个目录
- `os.listdir('.')`：列举当前目录下的文件和目录
- `os.path.join()`：把两个路径合成一个，注意这个方法比直接拼字符串更好，因为可以正确处理不同操作系统的路径分隔符（unix下是/，win下是\）
- `os.path.split()`：拆分出两个路径，同理这个方法比直接split更提倡使用
- `os.path.splitext()`：得到文件拓展名
- `os.rename()`：重命名文件
- `os.remove()`：删除文件



## 序列化


我们把变量从内存中变成可存储或传输的过程称之为序列化，在Python中叫pickling。序列化之后，就可以把序列化后的内容写入磁盘，或者通过网络传输到别的机器上。反过来，把变量内容从序列化的对象重新读到内存里称之为反序列化，即unpickling。


Python提供了`pickle`模块来实现序列化：


```python
>>> import pickle
>>> d = dict(name='Bob', age=20, score=88)

# 把任意对象序列化成一个bytes，然后，就可以把这个bytes写入文件。
>>> pickle.dumps(d)
b'\x80\x03}q\x00(X\x03\x00\x00\x00ageq\x01K\x14X\x05\x00\x00\x00scoreq\x02KXX\x04\x00\x00\x00nameq\x03X\x03\x00\x00\x00Bobq\x04u.'

# 把对象序列化后写入一个file-like Object：
>>> f = open('dump.txt', 'wb')
>>> pickle.dump(d, f)
>>> f.close()
```


当我们要把对象从磁盘读到内存时，可以先把内容读到一个bytes，然后用`pickle.loads()`方法反序列化出对象，也可以直接用`pickle.load()`方法从一个file-like Object中直接反序列化出对象。我们打开另一个Python命令行来反序列化刚才保存的对象：


```python
>>> f = open('dump.txt', 'rb')
>>> d = pickle.load(f)
>>> f.close()
>>> d
{'age': 20, 'score': 88, 'name': 'Bob'}
```


另一种实现序列化的方法是JSON：


```python
>>> import json
>>> d = dict(name='Bob', age=20, score=88)

# 返回一个str，内容就是标准的JSON
>>> json.dumps(d)
'{"age": 20, "score": 88, "name": "Bob"}'

# 类似的，dump()方法可以直接把JSON写入一个file-like Object。
```


要把JSON反序列化为Python对象，用loads()或者对应的load()方法，前者把JSON的字符串反序列化，后者从file-like Object中读取字符串并反序列化：


```python
>>> json_str = '{"age": 20, "score": 88, "name": "Bob"}'
>>> json.loads(json_str)
{'age': 20, 'score': 88, 'name': 'Bob'}
```


# 正则表达式


正则表达式是一种用来匹配字符串的强有力的武器。它的设计思想是用一种描述性的语言来给字符串定义一个规则，凡是符合规则的字符串，我们就认为它“匹配”了，否则，该字符串就是不合法的。


在正则表达式中，如果直接给出字符，就是精确匹配。用`\d`可以匹配一个数字，`\w`可以匹配一个字母或数字，所以：


- '00\d'可以匹配'007'，但无法匹配'00A'；
- '\d\d\d'可以匹配'010'；
- '\w\w\d'可以匹配'py3'；



`.`可以匹配任意字符，所以'py.'可以匹配'pyc'、'pyo'、'py!'等等。


来看一个复杂的例子：`\d{3}\s+\d{3,8}`。


- \d{3}表示匹配3个数字，例如'010'；
- \s可以匹配一个空格（也包括Tab等空白符），所以\s+表示至少有一个空格，例如匹配' '，' '等；
- \d{3,8}表示3-8个数字，例如'1234567'



要做更精确地匹配，可以用[]表示范围:


- `[0-9a-zA-Z\_]`可以匹配一个数字、字母或者下划线；
- `[0-9a-zA-Z\_]+`可以匹配至少由一个数字、字母或者下划线组成的字符串，比如'a100'，'0_Z'，'Py3000'等等；
- `[a-zA-Z\_][0-9a-zA-Z\_]*`可以匹配由字母或下划线开头，后接任意个由一个数字、字母或者下划线组成的字符串，也就是Python合法的变量；
- `[a-zA-Z\_][0-9a-zA-Z\_]{0, 19}`更精确地限制了变量的长度是1-20个字符（前面1个字符+后面最多19个字符）。
- `A|B`可以匹配A或B，所以`(P|p)ython`可以匹配'Python'或者'python'。
- `^`表示行的开头，`^\d`表示必须以数字开头。
- `$`表示行的结束，`\d$`表示必须以数字结束。



Python提供`re`模块，包含所有正则表达式的功能。使用Python的r前缀，就不用考虑转义的问题：


```python
s = r'ABC\-001' #  Python的字符串
#  对应的正则表达式字符串不变：
#  'ABC\-001'
```


`match()`方法判断是否匹配，如果匹配成功，返回一个`Match`对象，否则返回`None`：


```python
import re
re.match(r'^\d{3}\-\d{3,8}$', '010-12345')
# 返回<_sre.SRE_Match object; span=(0, 9), match='010-12345'>

re.match(r'^\d{3}\-\d{3,8}$', '010 12345')
# 返回None
```


正则表达式还有提取子串的强大功能。用()表示的就是要提取的分组（Group）。比如：


^(\d{3})-(\d{3,8})$分别定义了两个组，可以直接从匹配的字符串中提取出区号和本地号码。注意到group(0)永远是原始字符串，group(1)、group(2)……表示第1、2、……个子串。


正则匹配默认是贪婪匹配，也就是匹配尽可能多的字符。例如，匹配出数字后面的0：


```python
re.match(r'^(\d+)(0*)$', '102300').groups()
# 返回('102300', '')
```


由于`\d+`采用贪婪匹配，直接把后面的0全部匹配了，结果`0*`只能匹配空字符串了。


必须让`\d+`采用非贪婪匹配（也就是尽可能少匹配），才能把后面的0匹配出来，加个`?`就可以让`\d+`采用非贪婪匹配：


```python
re.match(r'^(\d+?)(0*)$', '102300').groups()
# 返回('1023', '00')
```


当我们在Python中使用正则表达式时，re模块内部会干两件事情：


1. 编译正则表达式，如果正则表达式的字符串本身不合法，会报错；
2. 用编译后的正则表达式去匹配字符串。



如果一个正则表达式要重复使用几千次，出于效率的考虑，我们可以预编译该正则表达式，接下来重复使用时就不需要编译这个步骤了，直接匹配：


```python
>>> import re
# 编译:
>>> re_telephone = re.compile(r'^(\d{3})-(\d{3,8})$')
# 使用：
>>> re_telephone.match('010-12345').groups()
('010', '12345')
>>> re_telephone.match('010-8086').groups()
('010', '8086')
```


# 进程和线程


## 多进程


由于Python是跨平台的，自然也应该提供一个跨平台的多进程支持。`multiprocessing`模块就是跨平台版本的多进程模块，它提供了一个Process类来代表一个进程对象，下面的例子演示了启动一个子进程并等待其结束：


```python
from multiprocessing import Process
import os

# 子进程要执行的代码
def run_proc(name):
    print('Run child process %s (%s)...' % (name, os.getpid()))

if __name__=='__main__':
    print('Parent process %s.' % os.getpid())
    p = Process(target=run_proc, args=('test',))
    print('Child process will start.')
    p.start() # 启动创建的Process实例子进程
    p.join() # 等待子进程结束后再继续往下运行，通常用于进程间的同步
    print('Child process end.')


"""
Parent process 928.
Child process will start.
Run child process test (929)...
Process end.
"""
```


如果要启动大量的子进程，可以用进程池的方式批量创建子进程：


```python
from multiprocessing import Pool
import os, time, random

def long_time_task(name):
    print('Run task %s (%s)...' % (name, os.getpid()))
    start = time.time()
    time.sleep(random.random() * 3)
    end = time.time()
    print('Task %s runs %0.2f seconds.' % (name, (end - start)))

if __name__=='__main__':
    print('Parent process %s.' % os.getpid())
    p = Pool(4) # Pool的默认大小，决定并行进程数量
    for i in range(5):
        p.apply_async(long_time_task, args=(i,))
    print('Waiting for all subprocesses done...')
    p.close() # 调用join()之前必须先调用close()，调用close()之后就不能继续添加新的Process了
    p.join() # 等待所有子进程执行完毕
    print('All subprocesses done.')

"""
Parent process 669.
Waiting for all subprocesses done...
Run task 0 (671)...
Run task 1 (672)...
Run task 2 (673)...
Run task 3 (674)...
Task 2 runs 0.14 seconds.
Run task 4 (673)...
Task 1 runs 0.27 seconds.
Task 3 runs 0.86 seconds.
Task 0 runs 1.41 seconds.
Task 4 runs 1.91 seconds.
All subprocesses done.
"""
```


很多时候，子进程并不是自身，而是一个外部进程。我们创建了子进程后，还需要控制子进程的输入和输出。`subprocess`模块可以让我们非常方便地启动一个子进程，然后控制其输入和输出。


```python
import subprocess

print('$ nslookup www.python.org')
r = subprocess.call(['nslookup', 'www.python.org'])
print('Exit code:', r)

"""
$ nslookup www.python.org
Server:		192.168.19.4
Address:	192.168.19.4#53

Non-authoritative answer:
www.python.org	canonical name = python.map.fastly.net.
Name:	python.map.fastly.net
Address: 199.27.79.223

Exit code: 0
"""
```


如果子进程还需要输入，则可以通过`communicate()`方法输入。下面的代码相当于在命令行执行命令nslookup，然后手动输入：


```
set q=mx
python.org
exit
```


```python
import subprocess

print('$ nslookup')
p = subprocess.Popen(['nslookup'], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
output, err = p.communicate(b'set q=mx\npython.org\nexit\n')
print(output.decode('utf-8'))
print('Exit code:', p.returncode)

"""
$ nslookup
Server:		192.168.19.4
Address:	192.168.19.4#53

Non-authoritative answer:
python.org	mail exchanger = 50 mail.python.org.

Authoritative answers can be found from:
mail.python.org	internet address = 82.94.164.166
mail.python.org	has AAAA address 2001:888:2000:d::a6


Exit code: 0
"""
```


Process之间肯定是需要通信的，操作系统提供了很多机制来实现进程间的通信。Python的`multiprocessing`模块包装了底层的机制，提供了Queue、Pipes等多种方式来交换数据。
以Queue为例，在父进程中创建两个子进程，一个往Queue里写数据，一个从Queue里读数据：


```python
from multiprocessing import Process, Queue
import os, time, random

# 写数据进程执行的代码:
def write(q):
    print('Process to write: %s' % os.getpid())
    for value in ['A', 'B', 'C']:
        print('Put %s to queue...' % value)
        q.put(value)
        time.sleep(random.random())

# 读数据进程执行的代码:
def read(q):
    print('Process to read: %s' % os.getpid())
    while True:
        value = q.get(True)
        print('Get %s from queue.' % value)

if __name__=='__main__':
    # 父进程创建Queue，并传给各个子进程：
    q = Queue()
    pw = Process(target=write, args=(q,))
    pr = Process(target=read, args=(q,))
    # 启动子进程pw，写入:
    pw.start()
    # 启动子进程pr，读取:
    pr.start()
    # 等待pw结束:
    pw.join()
    # pr进程里是死循环，无法等待其结束，只能强行终止:
    pr.terminate()

"""
Process to write: 50563
Put A to queue...
Process to read: 50564
Get A from queue.
Put B to queue...
Get B from queue.
Put C to queue...
Get C from queue.
"""
```


## 多线程


Python的标准库提供了两个模块：`_thread`和`threading`，`_thread`是低级模块，`threading`是高级模块，对`_thread`进行了封装。绝大多数情况下，我们只需要使用`threading`这个高级模块。


由于任何进程默认就会启动一个线程，我们把该线程称为主线程，主线程又可以启动新的线程，Python的`threading`模块有个`current_thread()`函数，它永远返回当前线程的实例。主线程实例的名字叫MainThread，子线程的名字在创建时指定，我们用LoopThread命名子线程。名字仅仅在打印时用来显示，完全没有其他意义。


```python
import time, threading

# 新线程执行的代码:
def loop():
    print('thread %s is running...' % threading.current_thread().name)
    n = 0
    while n < 5:
        n = n + 1
        print('thread %s >>> %s' % (threading.current_thread().name, n))
        time.sleep(1)
    print('thread %s ended.' % threading.current_thread().name)

print('thread %s is running...' % threading.current_thread().name)
t = threading.Thread(target=loop, name='LoopThread')
t.start()
t.join()
print('thread %s ended.' % threading.current_thread().name)

"""
thread MainThread is running...
thread LoopThread is running...
thread LoopThread >>> 1
thread LoopThread >>> 2
thread LoopThread >>> 3
thread LoopThread >>> 4
thread LoopThread >>> 5
thread LoopThread ended.
thread MainThread ended.
"""
```


多线程和多进程最大的不同在于，多进程中，同一个变量，各自有一份拷贝存在于每个进程中，互不影响，而多线程中，所有变量都由所有线程共享，所以，任何一个变量都可以被任何一个线程修改，因此，线程之间共享数据最大的危险在于多个线程同时改一个变量，把内容给改乱了。


以账户存、取的场景为例：


```python
import time, threading

# 假定这是你的银行存款:
balance = 0

# 由于线程的调度是由操作系统决定的，当t1、t2交替执行时，只要循环次数足够多，balance的结果就不一定是0了。
def change_it(n):
    # 先存后取，结果应该为0:
    global balance
    balance = balance + n
    balance = balance - n

def run_thread(n):
    for i in range(2000000):
        change_it(n)

t1 = threading.Thread(target=run_thread, args=(5,))
t2 = threading.Thread(target=run_thread, args=(8,))
t1.start()
t2.start()
t1.join()
t2.join()
print(balance)
```


两个线程同时一存一取，就可能导致余额不对，你肯定不希望你的银行存款莫名其妙地变成了负数，所以，我们必须确保一个线程在修改balance的时候，别的线程一定不能改。如果我们要确保balance计算正确，就要给`change_it()`上一把锁，当某个线程开始执行`change_it()`时，我们说，该线程因为获得了锁，因此其他线程不能同时执行`change_it()`，只能等待，直到锁被释放后，获得该锁以后才能改。由于锁只有一个，无论多少线程，同一时刻最多只有一个线程持有该锁，所以，不会造成修改的冲突。创建一个锁就是通过`threading.Lock()`来实现：


```python
lock = threading.Lock()

def run_thread(n):
    for i in range(100000):
        # 先要获取锁:
        lock.acquire()
        try:
            # ...
            change_it(n)
        finally:
            # 改完了一定要释放锁:
            lock.release()
```


因为Python的线程虽然是真正的线程，但解释器执行代码时，有一个GIL锁：Global Interpreter Lock，任何Python线程执行前，必须先获得GIL锁，然后，每执行100条字节码，解释器就自动释放GIL锁，让别的线程有机会执行。


GIL的全称是Global Interpreter Lock(全局解释器锁)，是一个关于数据安全的机制。它使得每个CPU在同一时间只能执行一个线程。在Python多线程下，每个线程的执行方式：


1. 获取GIL
2. 执行代码直到sleep或者是Python虚拟机将其挂起。
3. 释放GIL



可见，某个线程想要执行，必须先拿到GIL，并且在一个Python进程中，GIL只有一个。拿不到通行证的线程，就不允许进入CPU执行。所以，这个GIL全局锁实际上把所有线程的执行代码都给上了锁，多线程在Python中只能交替执行，即使100个线程跑在100核CPU上，也只能用到1个核。不过，也不用过于担心，Python虽然不能利用多线程实现多核任务，但可以通过多进程实现多核任务。多个Python进程有各自独立的GIL锁，互不影响。


## ThreadLocal


在多线程环境下，每个线程都有自己的数据。一个线程使用自己的局部变量比使用全局变量好，因为局部变量只有线程自己能看见，不会影响其他线程，而全局变量的修改必须加锁。ThreadLocal解决了参数在一个线程中各个函数之间互相传递的问题。ThreadLocal最常用的地方就是为每个线程绑定一个数据库连接，HTTP请求，用户身份信息等，这样一个线程的所有调用到的处理函数都可以非常方便地访问这些资源。


```python
import threading
    
# 创建全局ThreadLocal对象:
local_school = threading.local()

def process_student():
    # 获取当前线程关联的student:
    std = local_school.student
    print('Hello, %s (in %s)' % (std, threading.current_thread().name))

def process_thread(name):
    # 绑定ThreadLocal的student:
    local_school.student = name
    process_student()

t1 = threading.Thread(target= process_thread, args=('Alice',), name='Thread-A')
t2 = threading.Thread(target= process_thread, args=('Bob',), name='Thread-B')
t1.start()
t2.start()
t1.join()
t2.join()

"""
Hello, Alice (in Thread-A)
Hello, Bob (in Thread-B)
"""
```


全局变量`local_school`就是一个ThreadLocal对象，每个Thread对它都可以读写`student`属性，但互不影响。你可以把`local_school`看成全局变量，但每个属性如`local_school.student`都是线程的局部变量，可以任意读写而互不干扰，也不用管理锁的问题，ThreadLocal内部会处理。


## 多进程和多线程的选择


```
在多核的环境下，每次释放GIL锁，线程进行锁竞争、切换线程，会消耗资源，并且耗时很长。并且由于GIL锁存在，Python里一个进程永远只能同时执行一个线程(拿到GIL的线程才能执行)，比如CPU0释放GIL后，其他CPU上的线程都会进行竞争，但GIL可能会马上又被CPU0拿到，导致其他几个CPU上，被唤醒后的线程会等待到切换时间后又进入待调度状态。这就是为什么在多核CPU上，Python的多线程效率并不高的根本原因。

因此，通常来说Python下如果要充分利用多核CPU，广义的原则是多进程，每个进程有各自独立的GIL，互不干扰，这样就可以真正意义上的并行执行。不过具体的选择上还取决于使用场景，如果并发的是多个任务是CPU密集型，比如金融分析计算，多核意味着并行计算，因此多进程效率高；如果并发的多个任务是I/O密集型，比如socket这种网络I/O，很多时候都是在等待数据的返回，此时会释放GIL锁，其他线程可以继续执行，因此可以用多线程。

当然，如果条件合适的话，也可以使用协程代替多线程，应对I/O密集型的任务。
```


# 异步IO


## 协程


```
可以使用`yield`关键词。

实现了`__iter__`和`__next__`方法的对象都称为迭代器。迭代器是一个有状态的对象，在调用`next()`的时候返回下一个值，如果容器中没有更多元素了，则抛出StopIteration异常。而`yield`生成器其实是一种特殊的迭代器，但是不需要像迭代器一样实现`__iter__`和`__next__`方法，只需要使用关键字`yield`就可以。使用了生成器，在调用函数的时候不会一次性生成所有的元素，而是在每次调用`next()`才生成一个元素，这样能节省内存和CPU。一段`yield`的使用代码：

```python
def fib():
    prev, curr = 0, 1
    while True:
        yield curr
        curr, prev = prev + curr, curr

f = fib()
for i in range(10):
    print(next(f))
```

同时，生成式有一个`send()`方法，能够把一个值发送给生成器，这个值会变成`yield`表达式的值。

```python
def func():
    while True:
        print("before yield")
        x = yield
        print("after yield:",x)

    g = func()
    next(g) # 程序运行到yield并停在该处,等待下一个next
    g.send(1) # 给yield发送值1,这个值被赋值给了x，并且打印出来,然后继续下一次循环停在yield处
    g.send(2) # 给yield发送值2,这个值被赋值给了x，并且打印出来,然后继续下一次循环停在yield处
    next(g) # 没有给x赋值，执行print语句，打印出None,继续循环停在yield处

'''
before yield
after yield: 1
before yield
after yield: 2
before yield
after yield: None
before yield
'''
```

配合`yield`和`send`，实现一个生产者/消费者的例子：

```python
import time

def consumer():
    r = ''
    while True:
        n = yield r
        if not n:
            return
        print('[CONSUMER] Consuming %s...' % n)
        time.sleep(1)
        r = '200 OK'

def produce(c):
    c.next()
    n = 0
    while n < 5:
        n = n + 1
        print('[PRODUCER] Producing %s...' % n)
        r = c.send(n)
        print('[PRODUCER] Consumer return: %s' % r)
    c.close()

if __name__=='__main__':
    c = consumer()
    produce(c)

'''
[PRODUCER] Producing 1...
[CONSUMER] Consuming 1...
[PRODUCER] Consumer return: 200 OK
[PRODUCER] Producing 2...
[CONSUMER] Consuming 2...
[PRODUCER] Consumer return: 200 OK
[PRODUCER] Producing 3...
[CONSUMER] Consuming 3...
[PRODUCER] Consumer return: 200 OK
[PRODUCER] Producing 4...
[CONSUMER] Consuming 4...
[PRODUCER] Consumer return: 200 OK
[PRODUCER] Producing 5...
[CONSUMER] Consuming 5...
[PRODUCER] Consumer return: 200 OK
```

1. 调用consumer函数，consumer函数的返回是一个生成器，把这个生成器传入produce函数。
2. producer函数中调用next(c)启动生成器。
3. 计算n = n+1生成数据，一旦生产了数据，调用c.send(n)切换到consumer执行。
4. consumer函数中拿到数据后赋值给n，继续执行yield后面的语句。
5. consumer函数中打印消费的数据，并设置返回值r，回到循环的开始，通过yield把结果传回。
6. producer拿到consumer返回的值，继续生产下一个数据。
7. 5个数据生产完毕后，循环结束，通过c.close()关闭consumer，结束全过程。

`producer`和`consumer`函数在一个线程内执行，通过调用`send`方法和`yield`互相切换，实现协程的功能。
```


## asyncio(async / await)


asyncio的编程模型就是一个消息循环。我们从asyncio模块中直接获取一个EventLoop的引用，然后把需要执行的协程扔到EventLoop中执行，就实现了异步IO。


```python
import asyncio

@asyncio.coroutine
def hello():
    print("Hello world!")
    # 异步调用asyncio.sleep(1):
    r = yield from asyncio.sleep(1)
    print("Hello again!")

# 获取EventLoop:
loop = asyncio.get_event_loop()
# 执行coroutine
loop.run_until_complete(hello())
loop.close()
```


`@asyncio.coroutine`把一个generator标记为coroutine类型，然后，我们就把这个coroutine扔到EventLoop中执行。


`hello()`会首先打印出Hello world!，然后，`yield from`语法可以让我们方便地调用另一个generator。由于`asyncio.sleep()`也是一个coroutine，所以线程不会等待`asyncio.sleep()`，而是直接中断并执行下一个消息循环。当`asyncio.sleep()`返回时，线程就可以从`yield from`拿到返回值（此处是None），然后接着执行下一行语句。


把`asyncio.sleep(1)`看成是一个耗时1秒的IO操作，在此期间，主线程并未等待，而是去执行EventLoop中其他可以执行的coroutine了，因此可以实现并发执行。


为了简化并更好地标识异步IO，从Python 3.5开始引入了新的语法async和await，可以让coroutine的代码更简洁易读。对比一下之前的代码：


```python
# 旧语法
@asyncio.coroutine
def hello():
    print("Hello world!")
    r = yield from asyncio.sleep(1)
    print("Hello again!")

# 新语法
async def hello():
    print("Hello world!")
    r = await asyncio.sleep(1)
    print("Hello again!")
```


如果把asyncio.sleep()换成真正的IO操作，则多个coroutine就可以由一个线程并发执行。我们用asyncio的异步网络连接来获取sina、sohu和163的网站首页：


```python
import asyncio

@asyncio.coroutine
def wget(host):
    print('wget %s...' % host)
    connect = asyncio.open_connection(host, 80)
    reader, writer = yield from connect
    header = 'GET / HTTP/1.0\r\nHost: %s\r\n\r\n' % host
    writer.write(header.encode('utf-8'))
    yield from writer.drain()
    while True:
        line = yield from reader.readline()
        if line == b'\r\n':
            break
        print('%s header > %s' % (host, line.decode('utf-8').rstrip()))
    # Ignore the body, close the socket
    writer.close()

loop = asyncio.get_event_loop()
tasks = [wget(host) for host in ['www.sina.com.cn', 'www.sohu.com', 'www.163.com']]
loop.run_until_complete(asyncio.wait(tasks))
loop.close()


"""
wget www.sohu.com...
wget www.sina.com.cn...
wget www.163.com...
(等待一段时间)
(打印出sohu的header)
www.sohu.com header > HTTP/1.1 200 OK
www.sohu.com header > Content-Type: text/html
...
(打印出sina的header)
www.sina.com.cn header > HTTP/1.1 200 OK
www.sina.com.cn header > Date: Wed, 20 May 2015 04:56:33 GMT
...
(打印出163的header)
www.163.com header > HTTP/1.0 302 Moved Temporarily
www.163.com header > Server: Cdn Cache Server V2.0
...
"""
```
