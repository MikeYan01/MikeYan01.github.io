---
title: 计算机网络
tags: Notes
article_header:
  type: 
  image:
    src: 
---

计算机网络分层介绍。

<!--more-->

# OSI模型和基础概念


## 简介
OSI的全称是Open System Interconnect，中文名叫开放式系统互联，又叫OSI参考模型，是ISO组织在1985年研究的网络互连模型。该体系结构标准定义了网络互连的七层框架（物理层、数据链路层、网络层、传输层、会话层、表示层和应用层）。


## 分层与职责
![OSIModel.png](https://raw.githubusercontent.com/MikeYan01/mikeyan01.github.io/master/assets/images/计算机网络/OSIModel.png)

自底向上分层介绍：

- 物理层
利用传输介质，一般是机械、电子、定时接口的通信信道进行原始的比特流透明传输，为数据链路层提供物理连接。此处强调“透明”，希望是尽可能屏蔽具体传输介质和物理设备的差异，使得数据链路层不需要考虑网络的具体传输介质。



- 数据链路层
进行物理寻址，通过各种差错控制、流量控制等协议，把有差错的物理传输信道转变为可靠的数据链路。
数据链路层通常又分为两个子层，即介质访问控制（MAC）和逻辑链路控制（LLC）两个子层。MAC层主要解决共享网络中，多个用户对信道竞争的问题；LLC层主要负责建立和维护网络连接，执行差错校验，流量控制等等。

此外，数据链路层接收来自物理层的位流形式的数据，并封装成数据帧，传送到上一层；同样，也将来自上层的数据帧，拆装为位的数据流形式，转发到物理层
主要协议：隧道协议（PPTP），地址解析协议（ARP）


- 网络层
建立、维持和终止网络的连接，控制数据链路层与传输层之间的信息转发；通过路由选择算法，为报文或分组通过通信子网时选择最适当的路径。
主要协议：互联网协议（IPv4 & IPv6），路由协议（内部网关，包括RIP，OSPF，... + 外部网关，包括BGP等），控制消息协议（ICMP），组管理协议（IGMP）等



- 传输层
提供会话层和网络层之间的传输服务，即接受其中一方的数据，将数据报文传递到另一层。
在实际运用中，一般是负责两个主机进程之间的通信。因为一个主机可同时运行多个进程，因此运输层有复用（多个应用层进程可同时使用下面运输层的服务）和分用（把收到的信息分别交付给上面应用层中相应的进程）的功能。



传输层有两种主要协议，一种是较为可靠的、面向连接的TCP协议，另一种是面向无连接的UDP协议。


- 会话层
负责为不同机器上的用户进程之间建立及管理会话，保证应用程序之间的同步，同时协调交互工作方式，比如确定双工或者半双工等。



- 表示层
定义应用程序用来交换数据的格式，并负责协议转换、数据编码和数据压缩，使得应用层能正常使用接收到的数据。
例如传输图片的时候，图片格式GIF，JPEG等等就属于表示层。



- 应用层
直接向用户的应用进程提供服务，在其他6层工作的基础上建立与结束应用程序与操作系统之间的联系，协调各个应用程序之间的工作。
根据使用的传输层协议，可以列举一些常见应用层协议：
   - 基于TCP：HTTP，FTP，SMTP，POP3，Telnet
   - 基于UDP：DHCP，DNS



## 协议(Protocol)


一个协议定义了在两个或多个通信实体之间交换的报文格式和次序，以及在报文传输和/或接收或其他事件方面所采取的动作。
## 交换(Switching)

- 电路交换(Cirucuit Switching)：沿着端系统通信路径，为端系统之间通信所提供的资源(缓存，链路传输速率)在通信会话期间将会被预留						
- 分组交换(Packet Switching)：会话的报文按需使用上述资源，这将导致可能不得不等待(即排队)接入通信线路
# 数据链路层


## MAC


### MAC算法
共享网络中，同时只能有一台主机使用一条共享信道，用于传输数据。如果多台主机同时向信道上发送数据，会导致碰撞，所有主机的传输都可能会失败。MAC算法负责解决上述问题。


载波侦听多路访问/碰撞检测（CSMA/CD）算法（假设信道最长传输时间为a）：

1. 每台主机监听信道，如果监听到信道空闲就传输
1. 之后的2a时间内，主机继续监听信道
1. 如果监测到碰撞，主机会发送一个干扰信号，然后暂停传输
1. 主机会等待一个随机的时间，之后再次开始重传。随机时间范围由指数回退法决定，如果检测到了i次碰撞，等待的时间范围就是[0, 2 - 1] * a
1. 如果碰撞超过16次，传输失败



载波侦听多路访问/碰撞避免（CSMA/CA）算法：
常用于无线网络，无线站点每通过无线局域网发送完一帧后，要等到收到对方的确认帧后才能继续发送下一帧，即链路层确认。802.11规定，所有的站在完成发送后，必须再等待一段很短的时间(继续监听)才能发送下一帧。这段时间通称为帧间间隔IFS (InterFrame Space)，间隔的长短取决于该站要发送的帧的类型。高优先级帧需要等待的时间较短，因此可优先获得发送权，低优先级帧必须等待较长的时间。这样就减少了发生碰撞的机会。


ALOHA：
基于时隙，把时间分成若干个相同的时间片，所有用户在时间片开始时刻同步接入网络信道，若发生冲突，则必须等到下一个时间片开始时刻再发送。

### MAC地址
MAC地址全称是Media Access Control Address，又称为以太网地址或物理地址，是用来确认网络设备位置的地址，在网络中唯一标示一个网卡（生产网卡时，烧录MAC地址在网卡上）。


## ARP


地址解析协议(Address Resolution Protocol)，用于解析网络层IP地址来寻找数据链路层的MAC地址，实现了从IP地址到MAC地址的映射。
ARP工作的步骤：

1. 主机A向查询主机B的地址，于是在网络中广播了一个ARP request报文，报文中的目标IP地址是主机B的IP
1. 其他主机收到这个ARP request报文，发现目标IP与自己的不符，于是把主机A的IP地址以及MAC地址抄录到自己的ARP缓存表，之后丢弃这个报文
1. 主机B收到ARP request报文并发现目标IP与自己的相符，于是B向A直接发送一个单播ARP reply报文，其中包括了B的IP地址以及MAC地址等信息
1. 主机A收到ARP reply报文，把B的IP地址以及MAC地址抄录到自己的ARP缓存表。



有时，ARP报文也可以用来检测当前主机的IP地址是否与局域网中的其他主机冲突。待检测主机广播一个无关ARP request报文，把源IP地址和目的IP地址都设为自己的，如果收到了来自其他主机的ARP reply，则说明存在IP地址冲突。


# 2.5层协议：MPLS


### 简介
MPLS（Multi-Protocol Label Switching，多协议标签交换）指的是网络中利用标签引导数据进行快速交换和路由的协议。这样做的好处是避免了在路由表中频繁查询下一跳路由器地址的时间，提高传输效率。


### 工作原理
路由器则根据职责分为两种，一种是边缘标签路由(Label Edge Router, LER)，如果是入口(Ingress node)，将进行初始的路径选择以及MPLS标签的添加，如果是出口(Egress node)，则会去掉MPLS标签，使IP报文回到传统的路由系统中；另一种是标签交换路由(Label Switching Router, LSR)，负责进行MPLS转发。


MPLS网络中存在若干标签交换通道（Label Switched Path, LSP），每一条LSP是IP报文经过的LSR的集合，可以理解为报文在网络中被转发的路径。


MPLS的核心是在转发报文是使用标签交换技术。入口的LER基于源IP地址和目的地IP地址，能够预先规划出一条路径，并把路径信息添加在标签中，送往下一跳路由器。所有路由器都根据标签信息，执行特定的标签操作，再把报文转向下一跳节点，直到报文离开MPLS网络。标签操作类型包括push（把MPLS标签插入到IP报文头部），swap（用下一跳分配的标签替换当前栈顶标签）和pop（离开MPLS网络时，从IP报文头部剥离MPLS报文）。


### 快速重路由(Fast Reroute)
MPLS快速重路由是一种提供快速流量恢复的机制。MPLS路由器不仅会计算出常规路径，还会预先计算出一条备份路由路径。一旦网络中的某条链路或某个节点发生故障，受影响的数据包可以使用备份路径继续快速路由。


# 网络层


## IP报文的拆分


![IPfragmentation.png](https://raw.githubusercontent.com/MikeYan01/mikeyan01.github.io/master/assets/images/计算机网络/IPfragmentation.png)


## IP单播、组播、任播、广播


### 术语介绍与比较


这几个术语是IP网络中进行IP数据传输时，几种不同的通信模式。


单播：

- 点对点通信，即IP信息的接收和传输只在两个节点之间进行。网络中的交换机和路由器对数据只进行转发不进行复制
- 优点：服务器能及时相应客户请求，并且便于根据客户不同请求发送不同数据，实现个性化服务
- 缺点：速度慢，消耗的带宽大（想象同一份报文要发给100个客户机）



组播：

- 点对多通信，在一次传输中向多个接收者同时发送IP数据包。在发送时，有多播组这个概念，每个多播组就是一组当前数据包的接收者。每个组有一个标识符，一般来说是用一个224.0.0.0 ~ 239.255.255.255之间的IP地址作为这个标识符
- 网络中的交换机和路由器只向有需求者复制并转发其所需数据，既能一次将数据传输给多个组内的主机，又不影响其他组外的主机的通讯
- 优点：结合了单播和广播的优点，按需转发数据，节省带宽，并且可以在互联网上使用
- 缺点：没有纠错机制，发生丢包或错包之后不好弥补



广播：

- 点对多通信，使用广播地址255.255.255.255，将消息发送到在同一广播网络上的每个主机，网络对其中每一台主机发出的信号都进行无条件复制并转发，所有主机都可以接收到所有信息（不管是否需要）
- 优点：服务器不用单独向客户机单独发送数据，流量负载低；布置设备和维护设备也比较简单
- 缺点：广播不能在互联网上使用；每台主机转发了很多其他主机不需要的报文，浪费带宽



任播：

- 点对点通信，任播允许源节点向一组目标节点中的其中一个发送数据包，而这个节点由路由系统选择，对源节点透明。
- 优点：路由系统往往选择“最近”的节点为源节点提供服务，从而在一定程序上为源节点提供了更好的服务也减轻了网络负载。
- 缺点：不能保证每个目标节点都收到数据，并且速度慢



### IP组播路由算法
组播路由协议用于在路由器之间共享组信息，为组播数据报的分发提供路由，确保每一个组播路由器都能收到数据包。它的目标是找出一棵树，它连接所有附接主机属于组播组的路由器；根据这棵树路由组播包从发送者到达属于这棵组播树的所有主机。


一般有两种树：

- 共享组播树：构造出的树的链路和成本最小，但是组播源必须将组播数据首先发送给树根节点，之后树根节点再根据这棵树发送给所有节点。
- 基于源的树：以发送者为树根到每一个接收者的最短路径构成一棵转发树，从发送者到接收者的路径最优，但需要维护较多的状态信息。（使用Dijkstra算法构造）


### 管理IP组播成员(IGMP)
通过IGMP（Internet Group Management Protocol，互联网组管理协议）进行管理。这个协议让主机能和与其连接的路由器进行IGMP消息传输。


一般来说，有三种类型的IGMP消息：

- membership_query：路由器向所有与其连接的主机发送，检查这些主机目前加入的所有的组
- membership_report：主机用这种消息答复membership_query，汇报自己加了哪些组。也有可能主机刚加入一个组时，主动生成这种消息向路由器汇报
- leave_group：当一个主机离开一个组时，由主机或者路由器发送的一条可选的消息



## ICMP


互联网控制消息协议（Internet Control Message Protocol），用于在IP主机、路由器之间传递控制消息，包括网络是否通畅、主机是否可达、路由是否可用等等。
以Ping命令为例，输入Ping之后，源主机会构造一个ICMP Echo的请求数据包，由ICMP协议将数据包以及目标地址交给IP层协议；IP层协议将上述内容封装成IP数据包，通过ARP找出目标主机对应MAC地址，把报文传给数据链路层，由数据链路层根据MAC地址找到目标主机。目标主机检查MAC地址并与自己比对，比对成功后，层层返回，由ICMP协议构建ICMP reply包返回给源主机。


## RIP


路由信息协议（Routing Information Protocol）是一种较为简单的内部网关协议，基于距离矢量（Distance-Vector）算法，用跳数（Hop Count）作为度量来衡量到达目的网络的距离。每个设备到与其直连的设备之间跳数为0，然后每经过一个三层设备跳数增加1。
RIP规定度量值取0～15之间的整数，大于或等于16的跳数被定义为无穷大，即目的网络或主机不可达。由于这个限制，使得RIP不可能在大型网络中得到应用


## OSPF
### 简介


开发最短路径优先协议(Open Shortest Path First)是一种链路状态路由协议，基于Dijkstra算法来找出每个报文被转发到达所有目的地所需要的最短路径。具体而言，每个路由器都把自己当成根结点，根据累积的成本值（参考带宽/接口带宽）计算到达目的地的最小成本。
OSPF的核心是多种形式的链路状态通告（Link State Advertisement），LSA用来描述网络的拓扑信息。当路由器初始化或当网络结构发生变化（例如增减路由器，链路状态发生变化等）时，路由器会产生LSA包，该数据包里包含路由器上所有相连的链路，也即为所有端口的状态信息，这些LSA会在OSPF域中传播。不同类型的LSA共同描述了OSPF域内的网络拓扑结构。所有的LSA都保存在LSDB中，根据LSDB中的信息使用Dijkstra算法计算最佳路径，得到OSPF路由表。


### 报文类型

- Hello：建立和维护网络中的OSPF邻居关系，由每台主机周期性地发送。在支持组播或广播的物理网络上，Hello包使用组播地址（通常为224.0.0.5)发送
- Database Description：两台路由器初始建立邻居关系时，使用这个报文描述自己的LSDB，进行数据库同步
- Link State Request：两台路由器互相交换过DD报文之后，知道对方路由器有哪些LSA是本地的LSDB所缺少的，哪些LSA是已经失效的，这时需要发送LSR报文向对方请求自己所需的LSA
- Link State Update：用来向对方路由器发送其所需要的LSA。在支持组播和广播的链路上是以组播形式将LSA泛洪出去。内容是多条LSA的集合
- Link State Acknowledgement：对LSU中的LSA进行确认



### 默认路由
OSPF默认路由是0.0.0.0/0，它匹配了所有可能的前缀。如果没有为给定的目的地址设置特定的路由，或者目的地址不在路由表中，OSPF数据包将通过默认路由转发。一般来说，默认路由会将数据包转发到另一个路由器，直到有一个路由器知道如何将数据包转发到目的地，并据此将数据包发送出去。


### 网络中的被动接口
被动接口的设置是用来控制LSA和节约资源的。将接口设置为被动接口后，该接口将停止发送OSPF Hello数据包，并且不能与其他路由器建立邻居关系。因此，该接口也不会接收和发送OSPF数据包。如果在实际的网络中，有一些接口不需要接收OSPF路由信息，我们可以将其设置为被动，以此节省网络资源，减少路由器的负担。


# 传输层


## Socket
### Socket简介与通信流程
Socket是应用层和传输层之间的一个抽象层，把TCP/IP层的操作抽象成简单接口，供应用层调用。两个进程即便不在同一台计算机，只要有网络连接，也能相互通信。同时Socket的设计也能清楚的将服务器端和客户端区分开。


服务器端

1. 调用socket创建一个套接字
1. 调用bind给套接字绑定命名
1. 调用listen创建一个队列，用于存放所有的客户连接
1. 调用accept，等待客户端建立对套接字的连接，只有客户端连接到之前参数指定的套接字上时才返回，也就是说，如果套接字队列中没有未处理的连接，accept将阻塞直到有客户建立连接为止。注意此时会创建一个与原有的命名套接不同的新套接字，这个套接字只用于与这个特定客户端进行通信，而原来的命名套接字则被保留下来继续处理来自其他客户的连接。
1. 完成通信后，调用close关闭套接字



客户端

1. 调用socket创建一个套接字
1. 将服务器的命名套接字作为地址
1. 调用connect与服务器建立连接
1. 完成通信后，调用close关闭套接字



### Socket底层实现
一般来讲，我们可以认为TCP连接上发送的所有字节序列在某一瞬间被分成了3个FIFO的字节流队列：

1. SendQ：在发送端底层实现中缓存的字节，这些字节已经写到了OutputStream中，但还没被接收端成功接收。
1. RecvQ：在接收端底层实现中缓存的字节，这些字节等待分配到接收程序——即从InputStream中通过`read()`方法读取。
1. Delivered：接收者从输入流已经读取到的字节。



Socket的工作流程：

- 当我们调用OutputStream的`write()`方法时，将向SendQ追加字节。
- TCP协议负责将字节按顺序从SendQ移动到RecvQ。这里有重要的一点需要明确：这个转移过程无法由用户程序控制或直接观察到，并且在块中发生，这些块的大小在一定程度上独立于传递给`write()`方法的缓冲区大小。
- 接收程序从Socket的InputStream读取数据时，字节就从RecvQ移动到Delivered中，而转移的块的大小依赖于RecvQ中的数据量和传递给read()方法的缓冲区的大小。



不能假设在连接的一端将数据写入输出流和在另一端从输入流读出数据之间有任何的一致性。尤其是在发送端由单个输出流的`write()`方法传输的数据，可能会通过另一端的多个输入流的`read()`方法获取，而一个`read()`方法可能会返回多个`write()`方法传输的数据。


## TCP
### 简介与主要特点


TCP(Transmission Control Protocol, 传输控制协议)是一个可靠的、面向连接的、基于字节流的传输层通信协议。

- 端到端，因此总是一台sender，一台receiver
- 面向连接，有三次握手和四次挥手过程
- 可靠，能够保证传输的数据包按照顺序全部送达
- 拥塞控制，防止发送端将过多数据发出
   - 慢启动，连接开始时发送方维持一个拥塞窗口的变量`cwnd`，每收到一次ACK就指数倍增`cwnd`
   - 拥塞避免，让拥塞窗口缓慢增长，即每经过一个往返时间RTT就把发送方的拥塞窗口`cwnd`加1，这样拥塞窗口按线性规律缓慢增长。
   - 快速重传，如果收到同一个ACK超过3次就重新发送带有最小Seq Number的未确认包
   - 快速恢复，把慢启动的阈值`ssthresh`减半
- 流量控制，防止发送段发出的数据量超出接收端
   - 接收端有一个缓冲区，同时又一个滑动窗口变量`rwnd`。每次回应的ACK报文中就会附带这个窗口值，表示着自己此刻还能接收多少字节的报文。当这个窗口太小，那发送方只能按照这个窗口去发送数据
- 双工，一个连接中存在两个方向的数据传输



TCP报头结构：
![TCPheader.png](https://raw.githubusercontent.com/MikeYan01/mikeyan01.github.io/master/assets/images/计算机网络/TCPheader.png)


### Seq和ACK


初始序号:
当新连接建立的时候，第一个字节数据的序号称为ISN(Initial Sequence Number)，即初始序号。ISN一开始并不一定就是1。ISN的生成取决于时间与哈希算法，时间指的是一个计时器，每隔4毫秒加1。哈希算法则根据源IP、目的IP、源端口、目的端口生成一个随机数值。


序列号(Sequence Number): 32位，有两个作用：

- SYN为1时，是当前连接的ISN，数据的第一个字节序号是ISN + 1
- SYN是0时，是当前连接报文段累计数据包的字节数



确认号(Acknowledgment Number): 32位，有以下特点：

- 接收方期待的下一个报文段的序列号
- 在TCP协议中，一般采用累积确认的方式，即每传送多个连续TCP段，可以只对最后一个TCP段进行确认



### 三次握手、四次挥手

TCP三次握手过程状态图：
![TCP-handshake.png](https://raw.githubusercontent.com/MikeYan01/mikeyan01.github.io/master/assets/images/计算机网络/TCP-handshake.png)

TCP四次握手过程状态图：
![TCP-closing.png](https://raw.githubusercontent.com/MikeYan01/mikeyan01.github.io/master/assets/images/计算机网络/TCP-closing.png)


状态解释：

- LISTEN:       侦听来自远方的TCP端口的连接请求
- SYN-SENT:     在发送连接请求后等待匹配的连接请求
- SYN-RECEIVED: 在收到和发送一个连接请求后等待对方对连接请求的确认
- ESTABLISHED:  代表一个打开的连接
- FIN-WAIT-1:   等待远程TCP连接中断请求, 或先前的连接中断请求的确认
- FIN-WAIT-2:   从远程TCP等待连接中断请求
- CLOSE-WAIT:   等待从本地用户发来的连接中断请求，一般是等上层应用做好准备关闭连接
- CLOSING:      等待远程TCP对连接中断的确认
- LAST-ACK:     上层应用程序调用close关闭连接，发送FIN，等待远程TCP的连接中断请求的确认
- TIME-WAIT:    等待足够的时间以确保远程TCP接收到连接中断请求的确认
- CLOSED:        没有任何连接状态



三次握手详解：

1. 客户端向服务器端发送一个含有同步序列号(SYN)标志位的数据段给服务器端，向服务器端请求建立连接。数据包中，初始序列号(ISN)是客户端随机产生的值，确认号是0
1. 服务器端收到客户端的请求后，用一个带有确认应答（ACK）和同步序列号（SYN）标志位的数据段响应客户端。数据包中，序列号是服务器随机产生的一个值，确认号是客户端ISN + 1
1. 客户端收到这个数据段后，再发送一个确认应答，确认已收到服务器端的数据段。数据包中，序列号是服务器端返回的确认号 + 1，确认号是服务器的序列号 + 1



三次握手的的作用就是预告双方即将建立连接开始通信，并且双方都能明确自己和对方的收发能力是正常的；同时客户端和服务端交换初始序列号(Initial Sequence Number), 以便让对方知道接下来接收数据的时候如何按序列号组装数据。

1. 客户端发包，服务端收到了。服务端因此能得出结论：客户端的发送能力、服务端的接收能力是正常的
1. 服务端发包，客户端收到了。客户端因此能得出结论：服务端的接收、发送能力，客户端的接收、发送能力是正常的
1. 客户端发包，服务端收到了。服务端因此能得出结论：客户端的接收、发送能力，服务端的发送、接收能力是正常的



四次挥手详解：

1. 客户端完成数据传输，将控制位FIN设为1并发送给服务器，提出停止TCP连接的请求。数据包中，包含一个希望接收者看到的自己当前的序列号K. 同时还包含一个ACK表示确认对方最近一次发过来的数据。
1. 服务器端收到FIN后对其作出响应，确认客户端 -> 服务器端方向上的TCP连接将关闭，将ACK设为1并发送给客户端。数据包中，服务端将K值加1作为ACK序号值。
1. 服务器端再提出服务器端 -> 客户端方向上的TCP连接关闭请求，将FIN设为1并发送给客户端。数据包中，服务端发起自己的FIN段，ACK=K+1, Seq=L
1. 客户端收到FIN后对其作出响应，将ACK设为1并发送给服务器端，双方向的TCP连接关闭结束。数据包中，客户端确认。ACK=L+1



四次挥手确保两个方向的TCP连接都被关闭。


握手时，服务端在LISTEN状态下，收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端；
挥手时，当收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，己方是否现在关闭发送数据通道，需要上层应用来决定，因此，己方ACK和FIN一般都会分开发送。


### TCP粘包
保护消息边界：就是指传输协议把数据当作一条独立的消息在网上传输，接收端只能接收独立的消息。也就是说存在保护消息边界，接收端一次只能接收发送端发出的一个数据包。而面向流则是指无保护消息保护边界的，如果发送端连续发送数据，接收端有可能在一次接收动作中，会接收两个或者更多的数据包。


TCP粘包：发送方发送的若干包数据到接收方接收时粘成一包，从接收缓冲区看，后一包数据的头紧接着前一包数据的尾。这个只会在流传输中出现，并且既可能由发送方引起，也可能由接收方引起：

- 发送方引起的粘包是由TCP协议本身造成的，TCP为提高传输效率，发送方往往要收集到足够多的数据后才发送一包数据。若连续几次发送的数据都很少，通常TCP会根据优化算法把这些数据合成一包后一次发送出去，这样接收方就收到了粘包数据。
- 接收方引起的粘包是由于接收方用户进程不及时接收数据，从而导致粘包现象。这是因为接收方先把收到的数据放在系统接收缓冲区，用户进程从该缓冲区取数据，若下一包数据到达时前一包数据尚未被用户进程取走，则下一包数据放到系统接收缓冲区时就接到前一包数据之后，而用户进程根据预先设定的缓冲区大小从系统接收缓冲区取数据，这样就一次取到了多包数据。



解决方法：

- 发送固定长度的消息，指定好消息的长度，可以用while循环检查当前已发送的字节长度和剩余的未发的长度，确保不会遗漏
- 消息长度与消息一同发送，可以把int类型的消息长度转化成byte格式，用一个2字节的byte[]数组存储，发给接收方
- 在接收方添加一个线程，用于接受到数据后进行预处理
   - 将待处理的接收数据流（假设长度为m）强行转换成预定的结构数据形式，并从中取出结构数据长度字段（假设长度为n）
   - 若n < m，则表明数据流包含多包数据，从其头部截取n个字节存入临时缓冲区，剩余部分数据依此继续循环处理
   - 若n = m，则表明数据流内容恰好是一完整结构数据，直接将其存入临时缓冲区即可
   - 若n > m，则表明数据流内容尚不够构成一完整结构数据，需留待与下一包数据合并后再行处理



## UDP


### 简介
UDP(User Datagram Protocol, 用户数据报协议)是一个非连接的协议，无需建立连接就可以发送封装的IP数据包。具有以下特点：


- 传输数据之前源端和终端不建立连接(因此也没有握手过程)，需要传送时就抓取来自应用程序的数据，并尽快将其发送
- 在发送端，UDP传送数据的速度受应用程序生成数据的速度、 计算机的能力和传输带宽的限制； 在接收端，UDP把每个消息段放在队列中，应用程序每次从队列中读一个消息段。
- 不需要维护连接状态，包括收发状态等，因此一台服务机可同时向多个客户机传输相同的消息
- UDP使用尽最大努力交付，不保证可靠交付



UDP报头结构：
![UDPheader.png](https://raw.githubusercontent.com/MikeYan01/mikeyan01.github.io/master/assets/images/计算机网络/UDPheader.png)


### 优缺点和应用
优点：

- 没有建立连接的过程，简化了设计并且节省时间
- UDP报文头部很小，只有8字节，节省了很多额外开销
- 吞吐量不受拥塞控制算法的调节，只受应用软件生成数据的速率、传输带宽、源端和终端主机性能的限制



缺点:

- 丢包问题
- 即便数据成功传送，数据包的顺序也可能是错乱的



应用：

- DNS
- 流媒体应用(视频聊天软件，网络游戏等允许丢包，但注重传输率)



# 应用层


## HTTP和HTTPS


### HTTP简介与实现
HTTP协议指超文本传输协议(Hyper Text Transfer Protocol)，是从WEB服务器传输HTML到本地浏览器的传送协议。设计HTTP目的是提供一种发布和接收HTML页面的方法。
HTTP的实现基于TCP/IP通信协议，默认端口是80。一般的HTTP传输过程如下:

1. 客户端发起TCP请求，与服务端3次握手建立连接
1. 客户端向服务端发起HTTP请求。请求报文包括：
   - 请求行(Request line)，包括请求方法(GET, POST)，URL(统一资源定位符，定位具体的资源位置)，协议/版本
   - 请求头(Header line)，包括origin，user-agent, connection是否持久等等
   - 请求数据，GET中不包含，往往存在于POST方法中
```
GET /somedir/page.html HTTP/1.1
Host: www.someschool.edu
Connection: close
User-agent: Mozilla/4.0
Accept-language: fr
```

3. 服务端向客户端发送HTTP响应。响应报文包括：
   - 状态行(Status line)，包括协议/版本，状态码，响应状态信息
   - 响应头(Header line)，包括时间戳，返回内容的类型、编码、长度等信息
   - 响应正文



```
HTTP/1.1 200 OK
Connection: close
Date: Thu, 03 Jul 2003 12:00:15 GMT
Server: Apache/1.3.0 (Unix)
Last-Modified: Sun, 6 May 2007 09:23:24
Content-Length: 6821 Content-Type:text/html
```

4. 客户端将响应得到的HTML代码和资源渲染到前端



### HTTP的优缺点
优点：

- 简单快速：客户向服务器请求服务时，只需传送请求方法和路径
- 灵活：HTTP允许传输任意类型的数据对象。传输的类型由Content-Type加以标记



缺点:

- 无连接 & 无状态：限制每次连接只处理一个请求。服务器处理完请求，并收到客户的应答后，即断开连接，但是却不利于客户端与服务器保持会话连接；后续事务处理如果需要前面的信息，则必须重传数据 (使用Session和Cookie解决)
- 请求信息明文传输，容易被窃听截取
- 没有验证对方身份，存在冒充危险



### HTTPS简介与实现
SSL(Secure Socket Layer，安全套接字层)协议位于TCP/IP协议与各种应用层协议之间，为数据通讯提供安全支持。SSL后来发展成TLS（Transport Layer Security，传输层安全）。
HTTPS协议（HyperText Transfer Protocol over Secure Socket Layer）：一般理解为HTTP+SSL/TLS，通过SSL证书来验证服务器的身份，并为浏览器和服务器之间的通信进行加密。默认端口是443。实现流程如下：


1. 客户端通过URL访问服务器建立SSL连接
1. 服务端收到客户端请求后，会将网站支持的证书信息（证书中包含公钥）传送给客户端
1. 客户端的服务器开始协商SS连接的的信息加密等级，也就是信息加密的等级
1. 客户端产生随机对称密钥，再用公钥对这个对称密钥进行加密
1. 客户端将加密后的对称密钥发送给服务器，服务器用私钥解密出会话密钥



至此，客户端和服务器能够通过对称密钥加密的密文进行通信。


补充此处非对称加密的最常用算法：RSA算法，基于质数，即很难对很大的整数做因式分解，因此很可靠

### HTTPS的优缺点？
优点：

- 通信双方能够验证彼此的身份合法
- 通信的内容被加密，不易被窃听截取



缺点:

- HTTPS多次握手，导致页面加载时间显著变长
- SSL涉及的安全算法对服务器资源消耗大
- SSL证书需要钱，功能越强大费用越高


### Cookie


HTTP 服务器是无状态的，因此需要辅助使用Cookie保存用户信息。它类似一个用户令牌，是服务器在客户端本地机器上存储的一小段带有状态信息文本，并随着每次请求发送到服务器。服务器通过Cookie能够区别具体正在与哪一个客户端通信。

Cookie的四个组成部分：

- 在 HTTP 响应报文中有一个cookie首部行
- 在 HTTP 请求报文中有一个cookie首部行
- 在用户端系统中保留有一个cookie文件，由用户的浏览器管理
- 在 Web 站点有一个后端数据库



具体工作机制（往往是与Session结合）：


1. 浏览器首次访问页面，若页面使用cookie，则在返回信息中加上set-cookie: COOKIE_ID
1. 浏览器把COOKIE_ID写入本地 cookie 文件中
1. 浏览器再次访问该页面时，先查找cookie文件中有没有对应的cookie，若有则加上所带信息
1. 服务器收到消息后，根据COOKIE_ID查询数据库，从而找出用户的历史数据										



如果我们不设置Cookie过期时间，那么这个Cookie将不存放在硬盘上，当浏览器关闭的时候，Cookie就会消失。如果我们设置过期时间为若干天之后，那么这个Cookie会保存在客户端硬盘中，即使浏览器关闭，这个值仍然存在。
										
### Session, Cookie, Token的联系和区别？
Session是存放在服务器端的，用来存储用户信息的结构。最常见的Session ID保存方式是使用Cookie。

- 当浏览器第一次发送请求时，服务器自动生成了一个Session和一个Session ID用来唯一标识这个Session，并将其通过响应发送到浏览器
- 当浏览器第二次发送请求，会将前一次服务器响应中的Session ID放在请求中一并发送到服务器上，服务器从请求中提取出Session ID，并和保存的所有Session ID进行对比，找到这个用户对应的Session



Cookie往往可以与Session结合使用：

1. 客户端会发送一个HTTP请求到服务器端
1. 服务器端接受客户端请求后，建立一个Session，并发送一个HTTP响应到客户端，这个响应头，其中就包含Set-Cookie头部。该头部包含了Session ID
1. 在客户端发起的第二次请求，假如服务器给了set-Cookie，浏览器会自动在请求头中添加cookie
1. 服务器接收请求，分解cookie，验证信息，核对成功后返回response给客户端

---



Token也称作令牌，类似于临时的证书签名, 一种服务端无状态(服务端并不会保存身份认证相关的数据)的认证方式, 非常适合于REST API的场景


Token的组成:

- uid: 用户唯一身份标识
- time: 当前时间的时间戳
- sign: 签名, 使用hash/encrypt压缩成定长的十六进制字符串，以防止第三方恶意拼接
- 固定参数(可选): 将一些常用的固定参数加入到Token中是为了避免重复查库



Token的使用流程：

1. 用户登录，成功后服务器返回Token给客户端。
1. 客户端收到数据后保存在客户端
1. 客户端再次访问服务器，将Token放入headers中
1. 服务器端过滤校验。校验成功则返回请求数据，校验失败则返回错误码



## DNS


### 简介
DNS指域名系统(Domain Name System)。主要作用是根据域名查出IP地址，有了IP地址才能进行网络通信。


### 查询方式
DNS查询主要有纯递归查询和递归+迭代查询两种方式：


![DNS-query.png](https://raw.githubusercontent.com/MikeYan01/mikeyan01.github.io/master/assets/images/计算机网络/DNS-query.png)


递归和迭代的比较：

- 递归：客户端只发一次请求，要求对方给出最终结果。
- 迭代：客户端发出一次请求，对方如果没有授权回答，它就会返回一个能解答这个查询的其它名称服务器列表，客户端会再向返回的列表中发出请求，直到找到最终负责所查域名的名称服务器，从它得到最终结果。



因为纯递归查询比较耗时，因此现在使用比较少。而对于递归+迭代查询，主要流程如下：

1. 主机(地址为x.abc.com)要查询y.def.com的IP地址
1. 主机在本地DNS服务器(dns.abc.com)上查询y.def.com的地址。这个本地DNS服务器一般指电脑上网时IPv4或IPv6设置中填写的DNS地址，可能是手动指定或DHCP自动分配的。一般电脑直连运营商网络的话，本地DNS就是DHCP分配到的运营商的服务器地址
1. 本地DNS检查缓存是否有y.def.com的记录，如果没有，就直接询问DNS根服务器。DNS根服务器能指出y.def.com具体由哪一个顶级区域管理(.com)，并返回这个顶级域服务器的地址
1. 主机向顶级域服务器发起查询y.def.com的请求，顶级域服务器能返回二级域名服务器的地址(def.com)
1. 主机向二级域名服务器发起请求，查询y.def.com的IP地址，得到最终的IP地址结果。主机把这个IP地址写入DNS缓存，以备之后再次查询。



## 电子邮件相关协议


简单而言，Alice给Bob发送一封邮件的流程是：


1. Alice的代理，经过SMTP协议，把邮件传输到Alice的邮件服务器上
1. Alice的邮件服务器，经过SMTP协议，把邮件传输到Bob的邮件服务器上
1. Bob的邮件服务器，经过POP3、IMAP或HTTP协议，把邮件传输到Bob的代理上
### SMTP


Simple Mail Transfer Protocol（简单邮件传输协议），建立在FTP协议上，用来将邮件从发送方的邮件服务器传输到接收方的邮件服务器，或者是从发送方代理到发送方的邮件服务器。


### POP3


Post Office Protocol - Version 3（邮局协议版本3），将邮件从接收方的邮件服务器传输到接收方的用户代理。


### IMAP


Internet Mail Access Protocol（因特网邮件访问协议），与POP3的基础职责相同，但是提供了比POP3更丰富的功能，例如POP3只允许邮件客户端下载服务器上的邮件，但客户端的操作（删除/移动/标记已读等）不会反映到服务器上；而IMAP提供了服务器与客户端之间的双向通信。
										


## DHCP
### 简介与优点
DHCP(Dynamic Host Configuration Protocol，动态主机配置协议)，常用于中、大型网络中由服务器给每一台网络中与之连接的客户机自动分配IP地址。DHCP基于UDP协议。


优点：

- 网络管理员可以验证IP地址和其它配置参数，而不用去人工检查每台主机
- DHCP可以约束特定计算机使用特定IP地址，并且不会同时租借相同的IP地址给两台主机，避免冲突
- 客户机在不同子网间移动时不需要重新设置IP地址



### 分配IP地址的流程

1. DHCPDISCOVER：客户端在子网上广播一个DHCPDISCOVER数据包，以此来寻找合适的DHCP服务器。它表示客户端与服务器之间的DHCP交互开始
1. DHCPOFFER：每个收到DHCPDISCOVER包的DHCP服务器都会预留一个IP地址，并向客户机发送这个DHCPOFFER包。数据包中包含了IP地址以及网络配置设置
1. DHCPREQUEST：客户端可能会收到来自多个服务器的DHCPOFFER包，但它只接受其中一个DHCPOFFER包中包含的IP地址，并广播一个DHCPREQUEST包进行回复。DHCPREQUEST包不仅对被接受的DHCP服务器进行应答，还通知其他DHCP服务器它们的offer被拒绝
1. DHCPACK：被接受的DHCP服务器收到DHCPREQUEST数据包后，回复一个DHCPACK数据包。这是DHCP服务器的确认，授权客户机使用之前DHCPOFFER包中的网络配置。至此，客户端成功获得了一个IP地址



## BGP
### 简介
边界网关协议（Border Gateway Protocol, BGP）是互联网上一个核心的去中心化自治路由协议。先看几个相关概念：

- AS（Autonomous system）：自治系统，指在一个（有时是多个）组织管辖下的所有IP网络和路由器的全体，它们对互联网执行共同的路由策略。对于互联网来说，一个AS是一个独立的整体网络。而BGP实现的网络自治也是指各个AS自治。每个AS有自己唯一的编号ASN。
- IGP（Interior Gateway Protocol）：内部网关协议，在一个AS内部所使用的一种路由协议。一个AS内部也可以有多个路由器管理多个网络。各个路由器之间需要路由信息以知道子网络的可达信息。IGP就是用来管理这些路由。代表的实现有RIP和OSPF。
- EGP（Exterior Gateway Protocol）：外部网关协议，在多个AS之间使用的一种路由协议，现在已经被BGP取而代之。



由于BGP就是为了替换EGP而创建，它的地位与EGP相似。但是BGP也可以应用在一个AS内部。因此BGP又可以分为IBGP（Interior BGP ：同一个AS之间的连接）和EBGP（Exterior BGP：不同AS之间的BGP连接）。


既然EGP已经被替代了，那EBGP的存在比较好理解；但是IGP协议都还活得好好的（这里主要指OSPF等协议），那IBGP的意义何在？IGP的协议是针对同一个AS网络来设计的，一个自治网络的规模一般都不大，所以设计的时候就没有考虑大规模网络的情况。而当一个自治网络足够大时，OSPF存在性能瓶颈。此时，只有BGP的设计能满足大型网络的要求，所以大型私有IP网络内部可以使用IBGP。总的来说，这几类路由协议，小规模私有网络IGP，大规模私有网络IBGP，互联网EBGP。

### 工作原理
BGP路由是基于AS路径(AS Path)来完成的。AS路径是到达一条路由的ASN列表。来自不同AS的两个路由器之间有一条路径，这条路径可能会穿越若干AS。AS路径包括了这条路由路径上需要穿越的所有AS。


BGP路由存储在BGP路由器的数据库中，每条BGP路由都包含了目的地AS，下一跳和完整的AS Path。当BGP路由器收到了一条路由信息，检查路径发现包含了自己的AS号，那它就能判定这是一条自己曾经发出的路由信息，收到的这条路由信息会被丢弃；反之，将其发送给下一跳AS。


BGP基于路径矢量，举个例子，如果BGP路由器收到两条路由信息，目的网络一样，但是路径不一样，一个是AS1->AS3->AS2，另一个是AS1->AS2，如果没有其他的特殊策略，BGP路由器会选用AS1->AS2这条路由信息。


### 优点

- 灵活，可以跨越多跳路由器建立邻居关系，并在路由中携带丰富的属性，适应不同场景的需求
- 高效，丰富的路由策略能够使得不同场景下都能快速传递路由信息
- 稳定，避免路由环路，保证能将数据包传到目的地



# 无线网（802.11）


### 无线网通信使用CSMA/CA的原因

- 无线信道中信号强度动态范围很大，适配器接受的信号强度远远小于发送信号的强度，如果要在无线网的适配器上实现碰撞检测功能，硬件成本会非常大。
- 无线电波能向所有方向传播，由于各种障碍物的存在，电磁波传播距离受限，这导致碰撞检测很可能出现错误：检测到信道空闲，其实并不空闲（隐藏站问题）；而检测到信道忙，其实并不忙（暴露站问题）。



# 在浏览器输入URL回车之后发生了什么


1. 浏览器层面的操作
   - URL解析：首先判断你输入的是一个合法的 URL 还是一个待搜索的关键词，并且根据你输入的内容进行自动完成、字符编码等操作。
   - 安全检查：访问限制，是否强制使用HTTPS，...
   - 检查缓存是否过期



2. DNS查询域名对应的IP地址
浏览器缓存 -> 操作系统缓存 -> 路由器缓存 -> ISP缓存 -> 根域名服务器（递归+迭代）



3. 依照TCP/IP协议传输
TCP/IP分为四层，在发送数据时，每层都要对数据进行封装。



每一层的甄别标准：

   - 应用层：根据TCP/UDP的端口号甄别
   - 传输层：根据TCP/UDP头部甄别
   - 网络层：根据IP头部16位字段甄别
   - 链路层：根据以太网帧头部的2字节的类型字段甄别



每一层的构造

   1. 应用层：浏览器会开始构造一个HTTP报文
   1. 传输层：发起一条到达服务器的TCP连接，为了方便传输，会对数据进行分割（以报文段为单位），并标记编号，方便服务器接受时能够准确地还原报文信息。
   1. 网络层：IP协议查询MAC地址，将数据段打包，并加入源及目标的IP地址，并且负责寻找传输路线。判断目标地址是否与当前地址处于同一网络中，是的话直接根据MAC地址发送，否则使用路由表查找下一跳地址，以及使用 ARP 协议查询它的MAC地址。
   1. 链路层：根据以太网协议将数据分为以“帧”为单位的数据包，每一帧分为两个包含头部(数据包的发送者、接受者、数据类型)和数据段



![TCP-transmission.png](https://raw.githubusercontent.com/MikeYan01/mikeyan01.github.io/master/assets/images/计算机网络/TCP-transmission.png)

4. 服务器响应
   - 接受TCP报文后，会对连接进行处理，对HTTP协议进行解析（请求方法、域名、路径等）
   - 看是否需要重定向，如果服务器配置了HTTP重定向，就会返回一个301永久重定向响应，浏览器就会根据响应，重新发送HTTP请求，重复以上流程
   - 查看URL重写规则，如果请求的文件是真实存在的，会直接把这个文件返回；否则服务器会按照规则把请求重写到另一个REST风格的URL上。



5. 浏览器接受响应
   - 查看Response header，根据不同状态码做不同的事（比如上面提到的重定向）
   - 如果响应资源进行了压缩（比如 gzip），还需要进行解压
   - 对响应资源做缓存
   - 根据响应资源里的MIME类型去解析响应内容（比如 HTML、Image各有不同的解析方式）



6. 渲染页面
HTML解析，CSS解析，JavaScript的执行
